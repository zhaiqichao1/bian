import os
import time
import json
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from binance.client import Client
from binance.exceptions import BinanceAPIException
import schedule
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import ta
import logging
import pickle
import argparse
import threading
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
from imblearn.over_sampling import SMOTE
import sys
import select

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("bitcoin_prediction.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# é…ç½®æ–‡ä»¶
CONFIG_FILE = 'config.json'

# é»˜è®¤é…ç½® - ğŸ”§ æŠ€æœ¯æ”¹è¿›ï¼šå¢åŠ å†å²æ•°æ®è·å–èŒƒå›´
DEFAULT_CONFIG = {
    'api_key': '',
    'api_secret': '',
    'symbol': 'BTCUSDT',
    'intervals': ['1m', '5m', '15m'],
    'lookback_hours': 72,  # ğŸ”§ ä»24å°æ—¶å¢åŠ åˆ°72å°æ—¶ï¼Œç¡®ä¿è¶³å¤Ÿçš„å†å²æ•°æ®
    'prediction_minutes': 10,
    'hidden_size': 128,
    'num_layers': 2,
    'dropout': 0.2,
    'learning_rate': 0.001,
    'batch_size': 32,
    'epochs': 50,
    'sequence_length': 10,
    'trade_amount': 100,
    'stop_loss': 0.02,
    'take_profit': 0.03,
    'min_confidence_threshold': 60,  # ğŸ”§ æ–°å¢ï¼šæœ€ä½ç½®ä¿¡åº¦é—¨æ§›
    'enhanced_sentiment_enabled': True,  # ğŸ”§ æ–°å¢ï¼šå¯ç”¨å¢å¼ºæƒ…ç»ªåˆ†æ
    'soft_confidence_floor': 15,  # ğŸ”§ æ–°å¢ï¼šç½®ä¿¡åº¦è½¯ä¸‹é™
    'fear_greed_weight': 0.1,  # ğŸ”§ æ–°å¢ï¼šææ…Œè´ªå©ªæŒ‡æ•°æƒé‡
    'bet_amount': 5,  # å›ºå®šæŠ•æ³¨é‡‘é¢ä¸º5u
    'payout_ratio': 0.8,  # äº‹ä»¶åˆçº¦ç›ˆåˆ©ç‡80%
    'big_trade_threshold': 0.01,  # å¤§å•äº¤æ˜“é˜ˆå€¼ï¼Œå•ä½BTC (çº¦1000ç¾å…ƒ)
}

# åŠ è½½æˆ–åˆ›å»ºé…ç½®
def load_config():
    if os.path.exists(CONFIG_FILE):
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            config = json.load(f)
            # åˆå¹¶é»˜è®¤é…ç½®å’Œå·²æœ‰é…ç½®
            for key, value in DEFAULT_CONFIG.items():
                if key not in config:
                    config[key] = value
    else:
        config = DEFAULT_CONFIG
        save_config(config)
    return config

# ä¿å­˜é…ç½®
def save_config(config):
    with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=4, ensure_ascii=False)

# LSTMæ¨¡å‹å®šä¹‰ - å‡çº§ä¸ºBi-LSTM + Attention
class EnhancedLSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):
        super(EnhancedLSTMModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # Bi-LSTMå±‚
        self.lstm = nn.LSTM(
            input_size, 
            hidden_size, 
            num_layers, 
            batch_first=True, 
            dropout=dropout,
            bidirectional=True  # åŒå‘LSTM
        )
        
        # Attentionæœºåˆ¶
        self.attention = nn.MultiheadAttention(
            embed_dim=hidden_size * 2,  # åŒå‘LSTMè¾“å‡ºç»´åº¦
            num_heads=4,
            dropout=dropout,
            batch_first=True
        )
        
        # ç‰¹å¾èåˆå±‚
        self.feature_fusion = nn.Sequential(
            nn.Linear(hidden_size * 2, hidden_size),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(dropout)
        )
        
        # è¾“å‡ºå±‚
        self.fc = nn.Linear(hidden_size // 2, output_size)
        self.sigmoid = nn.Sigmoid()
        
    def forward(self, x):
        batch_size = x.size(0)
        
        # åˆå§‹åŒ–åŒå‘LSTMéšè—çŠ¶æ€
        h0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers * 2, batch_size, self.hidden_size).to(x.device)
        
        # Bi-LSTMå‰å‘ä¼ æ’­
        lstm_out, _ = self.lstm(x, (h0, c0))  # [batch, seq_len, hidden_size*2]
        
        # Self-Attentionæœºåˆ¶
        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)
        
        # å–æœ€åæ—¶é—´æ­¥çš„è¾“å‡º
        last_output = attn_out[:, -1, :]  # [batch, hidden_size*2]
        
        # ç‰¹å¾èåˆ
        fused_features = self.feature_fusion(last_output)
        
        # æœ€ç»ˆé¢„æµ‹
        output = self.fc(fused_features)
        output = self.sigmoid(output)
        
        return output

# ä¿æŒå‘åå…¼å®¹
class LSTMModel(EnhancedLSTMModel):
    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):
        super().__init__(input_size, hidden_size, num_layers, output_size, dropout)

# æ–°å¢ï¼šå¤šåˆ†ç±»æ ‡ç­¾ç³»ç»Ÿ
class EnhancedLabelProcessor:
    """å¢å¼ºçš„æ ‡ç­¾å¤„ç†å™¨ - æ”¯æŒå¤šç»´åº¦åˆ†ç±»"""
    
    def __init__(self):
        pass
    
    def create_enhanced_labels(self, df, prediction_minutes=10):
        """åˆ›å»ºå¢å¼ºçš„å¤šç»´åº¦æ ‡ç­¾"""
        labels = {}
        
        # 1. åŸºç¡€æ¶¨è·Œæ ‡ç­¾ (äºŒåˆ†ç±»)
        future_prices = df['close'].shift(-prediction_minutes)
        current_prices = df['close']
        price_changes = (future_prices - current_prices) / current_prices
        
        # å¤„ç†NaNå€¼
        valid_mask = ~(price_changes.isna() | future_prices.isna())
        
        labels['direction'] = (price_changes > 0).astype(int)
        labels['direction'] = labels['direction'].fillna(0)  # NaNå¡«å……ä¸º0
        
        # 2. æ¶¨å¹…å¤§å°æ ‡ç­¾ (å¤šåˆ†ç±»)
        price_change_pct = price_changes * 100
        price_change_pct = price_change_pct.fillna(0)  # å…ˆå¡«å……NaN
        
        labels['magnitude'] = pd.cut(price_change_pct, 
                                   bins=[-float('inf'), -0.5, -0.2, 0.2, 0.5, float('inf')],
                                   labels=[0, 1, 2, 3, 4], include_lowest=True)
        labels['magnitude'] = labels['magnitude'].fillna(2).astype(int)  # NaNå¡«å……ä¸ºéœ‡è¡(2)
        
        # 3. æ³¢åŠ¨ç‡æ ‡ç­¾ (ä¸‰åˆ†ç±»)
        rolling_std = df['close'].rolling(20).std()
        volatility_pct = rolling_std / df['close'] * 100
        volatility_pct = volatility_pct.fillna(1)  # å¡«å……é»˜è®¤æ³¢åŠ¨ç‡
        
        labels['volatility'] = pd.cut(volatility_pct,
                                    bins=[0, 1, 2, float('inf')],
                                    labels=[0, 1, 2], include_lowest=True)
        labels['volatility'] = labels['volatility'].fillna(1).astype(int)  # NaNå¡«å……ä¸ºä¸­ç­‰æ³¢åŠ¨(1)
        
        # 4. è¶‹åŠ¿å¼ºåº¦æ ‡ç­¾ (ä¸‰åˆ†ç±»)
        ma_short = df['close'].rolling(5).mean()
        ma_long = df['close'].rolling(20).mean()
        trend_strength = (ma_short - ma_long) / ma_long * 100
        trend_strength = trend_strength.fillna(0)  # å¡«å……ä¸ºæ— è¶‹åŠ¿
        
        labels['trend'] = pd.cut(trend_strength,
                               bins=[-float('inf'), -1, 1, float('inf')],
                               labels=[0, 1, 2], include_lowest=True)
        labels['trend'] = labels['trend'].fillna(1).astype(int)  # NaNå¡«å……ä¸ºéœ‡è¡(1)
        
        return labels

# æ–°å¢ï¼šæƒ…ç»ªåˆ†ææ¨¡å— - ğŸ”§ æŠ€æœ¯æ”¹è¿›ï¼šæ›´ä¸°å¯Œçš„æƒ…ç»ªæŒ‡æ ‡
class MarketSentimentAnalyzer:
    """å¸‚åœºæƒ…ç»ªåˆ†æå™¨ - å¢å¼ºç‰ˆ"""
    
    def __init__(self, api):
        self.api = api
        
    def analyze_order_book_sentiment(self, symbol='BTCUSDT'):
        """åˆ†æè®¢å•ç°¿æƒ…ç»ª - ğŸ”§ å¢å¼ºä¹°å¢™/å–å¢™åˆ†æ"""
        try:
            depth = self.api.get_order_book(symbol, limit=100)
            
            bids = depth.get('bids', [])
            asks = depth.get('asks', [])
            
            if not bids or not asks:
                return self._get_default_sentiment()
            
            # åŸºç¡€ä¹°å–ç›˜åˆ†æ
            bid_volume = sum([float(bid[1]) for bid in bids[:10]])  # å‰10æ¡£ä¹°å•
            ask_volume = sum([float(ask[1]) for ask in asks[:10]])  # å‰10æ¡£å–å•
            
            # ğŸ”§ æ–°å¢ï¼šä¹°å¢™/å–å¢™åˆ†æ
            # åˆ†æä¸åŒä»·æ ¼å±‚çº§çš„è®¢å•åˆ†å¸ƒ
            current_price = float(bids[0][0]) if bids else 0
            
            # ä¹°å¢™åˆ†æï¼šè·ç¦»å½“å‰ä»·æ ¼1%ä»¥å†…çš„å¤§é¢ä¹°å•
            buy_wall_volume = 0
            for bid in bids:
                price, volume = float(bid[0]), float(bid[1])
                if current_price - price <= current_price * 0.01:  # 1%ä»¥å†…
                    if volume > 10:  # å¤§é¢è®¢å•
                        buy_wall_volume += volume
            
            # å–å¢™åˆ†æï¼šè·ç¦»å½“å‰ä»·æ ¼1%ä»¥å†…çš„å¤§é¢å–å•
            sell_wall_volume = 0
            for ask in asks:
                price, volume = float(ask[0]), float(ask[1])
                if price - current_price <= current_price * 0.01:  # 1%ä»¥å†…
                    if volume > 10:  # å¤§é¢è®¢å•
                        sell_wall_volume += volume
            
            # ğŸ”§ æ–°å¢ï¼šæ·±åº¦ä¸å¹³è¡¡åˆ†æ
            # åˆ†æ5ä¸ªä»·æ ¼å±‚çº§çš„è®¢å•åˆ†å¸ƒ
            deep_bid_volume = sum([float(bid[1]) for bid in bids[:50]])  # å‰50æ¡£
            deep_ask_volume = sum([float(ask[1]) for ask in asks[:50]])
            
            total_volume = bid_volume + ask_volume
            if total_volume == 0:
                return self._get_default_sentiment()
                
            sentiment_score = bid_volume / total_volume  # ä¹°ç›˜å æ¯”
            book_imbalance = (bid_volume - ask_volume) / total_volume
            
            # ğŸ”§ æ–°å¢ï¼šä¹°å¢™/å–å¢™å¼ºåº¦
            wall_ratio = buy_wall_volume / max(sell_wall_volume, 1)
            deep_imbalance = (deep_bid_volume - deep_ask_volume) / max(deep_bid_volume + deep_ask_volume, 1)
            
            return {
                'sentiment_score': sentiment_score,
                'book_imbalance': book_imbalance,
                'bid_volume': bid_volume,
                'ask_volume': ask_volume,
                'buy_wall_volume': buy_wall_volume,  # ğŸ”§ æ–°å¢
                'sell_wall_volume': sell_wall_volume,  # ğŸ”§ æ–°å¢
                'wall_ratio': wall_ratio,  # ğŸ”§ æ–°å¢
                'deep_imbalance': deep_imbalance,  # ğŸ”§ æ–°å¢
            }
        except Exception as e:
            logging.warning(f"âš ï¸ è®¢å•ç°¿æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
            return self._get_default_sentiment()
    
    def analyze_funding_rate_sentiment(self, symbol='BTCUSDT'):
        """åˆ†æèµ„é‡‘è´¹ç‡æƒ…ç»ªï¼ˆéœ€è¦æœŸè´§APIï¼‰"""
        try:
            # ğŸ”§ å¯ä»¥é›†æˆå¸å®‰æœŸè´§APIè·å–èµ„é‡‘è´¹ç‡
            # èµ„é‡‘è´¹ç‡ä¸ºæ­£è¡¨ç¤ºå¤šå¤´æƒ…ç»ªï¼Œä¸ºè´Ÿè¡¨ç¤ºç©ºå¤´æƒ…ç»ª
            return {'funding_rate': 0.0}  # å ä½ç¬¦
        except:
            return {'funding_rate': 0.0}
    
    def get_fear_greed_index(self):
        """ğŸ”§ æ–°å¢ï¼šè·å–ææ…Œè´ªå©ªæŒ‡æ•°ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰"""
        try:
            # è¿™é‡Œå¯ä»¥é›†æˆçœŸå®çš„Fear & Greed Index API
            # ä¾‹å¦‚ï¼šAlternative.me API
            # ç›®å‰ä½¿ç”¨åŸºäºæŠ€æœ¯æŒ‡æ ‡çš„æ¨¡æ‹Ÿå®ç°
            
            # è·å–æœ€è¿‘ä»·æ ¼æ•°æ®è®¡ç®—ç®€åŒ–çš„ææ…Œè´ªå©ªæŒ‡æ•°
            klines = self.api.client.get_klines(symbol='BTCUSDT', interval='1h', limit=24)
            if not klines:
                return 50  # ä¸­æ€§å€¼
            
            df = pd.DataFrame(klines, columns=[
                'open_time', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_asset_volume', 'number_of_trades',
                'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'
            ])
            
            df['close'] = pd.to_numeric(df['close'])
            df['volume'] = pd.to_numeric(df['volume'])
            
            # ç®€åŒ–çš„ææ…Œè´ªå©ªæŒ‡æ•°è®¡ç®—
            # åŸºäºä»·æ ¼åŠ¨é‡ã€æ³¢åŠ¨ç‡ã€æˆäº¤é‡ç­‰å› ç´ 
            
            # 1. ä»·æ ¼åŠ¨é‡ (0-25åˆ†)
            price_change_24h = (df['close'].iloc[-1] - df['close'].iloc[0]) / df['close'].iloc[0]
            momentum_score = min(25, max(0, (price_change_24h + 0.1) * 125))
            
            # 2. æ³¢åŠ¨ç‡ (0-25åˆ†) - ä½æ³¢åŠ¨ç‡è¡¨ç¤ºè´ªå©ª
            volatility = df['close'].pct_change().std()
            volatility_score = min(25, max(0, 25 - volatility * 1000))
            
            # 3. æˆäº¤é‡ (0-25åˆ†) - é«˜æˆäº¤é‡è¡¨ç¤ºå¸‚åœºæ´»è·ƒ
            avg_volume = df['volume'].mean()
            recent_volume = df['volume'].iloc[-6:].mean()  # æœ€è¿‘6å°æ—¶
            volume_ratio = recent_volume / avg_volume if avg_volume > 0 else 1
            volume_score = min(25, max(0, volume_ratio * 12.5))
            
            # 4. å¸‚åœºä¸»å¯¼åœ°ä½ (0-25åˆ†) - ç®€åŒ–ä¸ºå›ºå®šå€¼
            dominance_score = 12.5  # ä¸­æ€§å€¼
            
            fear_greed_index = momentum_score + volatility_score + volume_score + dominance_score
            fear_greed_index = max(0, min(100, fear_greed_index))
            
            return fear_greed_index
            
        except Exception as e:
            logging.warning(f"âš ï¸ ææ…Œè´ªå©ªæŒ‡æ•°è®¡ç®—å¤±è´¥: {e}")
            return 50  # è¿”å›ä¸­æ€§å€¼
    
    def get_social_sentiment(self):
        """ğŸ”§ æ–°å¢ï¼šç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æï¼ˆå ä½ç¬¦ï¼‰"""
        try:
            # è¿™é‡Œå¯ä»¥é›†æˆTwitter APIã€Telegramé¢‘é“åˆ†æç­‰
            # ç›®å‰è¿”å›ä¸­æ€§å€¼
            return {
                'twitter_sentiment': 0.5,  # 0-1ï¼Œ0.5ä¸ºä¸­æ€§
                'telegram_mentions': 0,
                'reddit_sentiment': 0.5,
                'social_volume': 0
            }
        except:
            return {
                'twitter_sentiment': 0.5,
                'telegram_mentions': 0,
                'reddit_sentiment': 0.5,
                'social_volume': 0
            }
    
    def _get_default_sentiment(self):
        """è¿”å›é»˜è®¤æƒ…ç»ªæ•°æ®"""
        return {
            'sentiment_score': 0.5, 
            'book_imbalance': 0, 
            'bid_volume': 0, 
            'ask_volume': 0,
            'buy_wall_volume': 0,
            'sell_wall_volume': 0,
            'wall_ratio': 1.0,
            'deep_imbalance': 0,
        }

# æ•°æ®é›†ç±»
class TimeSeriesDataset(Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y
    
    def __len__(self):
        return len(self.X)
    
    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

# å¢å¼ºçš„å¸å®‰APIäº¤äº’ç±»
class EnhancedBinanceAPI:
    def __init__(self, api_key, api_secret, config):
        self.client = Client(api_key, api_secret)
        self.config = config
        self.websocket_data = {}
        self.big_trades = []
        self.market_depth = {}
        
    def get_multi_timeframe_data(self, symbol, intervals, start_str):
        """è·å–å¤šæ—¶é—´å‘¨æœŸæ•°æ®"""
        data = {}
        for interval in intervals:
            try:
                klines = self.client.get_historical_klines(symbol, interval, start_str)
                if klines:
                    data[interval] = klines
                    logging.info(f"ğŸ“Š è·å–{interval}æ•°æ®: {len(klines)}æ¡è®°å½•")
            except BinanceAPIException as e:
                logging.error(f"âŒ è·å–{interval}æ•°æ®å¤±è´¥: {e}")
        return data
    
    def get_recent_trades(self, symbol, limit=1000):
        """è·å–æœ€è¿‘æˆäº¤è®°å½•ï¼Œæ£€æµ‹å¤§å•"""
        try:
            trades = self.client.get_recent_trades(symbol=symbol, limit=limit)
            big_trades = []
            
            # ç¡®ä¿configä¸­æœ‰big_trade_thresholdï¼Œå¦‚æœæ²¡æœ‰åˆ™è®¾ç½®é»˜è®¤å€¼
            if 'big_trade_threshold' not in self.config:
                self.config['big_trade_threshold'] = 0.01  # é»˜è®¤0.01 BTCä¸ºå¤§å•é˜ˆå€¼
                logging.info(f"âš ï¸ æœªæ‰¾åˆ°å¤§å•é˜ˆå€¼é…ç½®ï¼Œè®¾ç½®é»˜è®¤å€¼ä¸º {self.config['big_trade_threshold']} BTC")
            
            # ç¡®ä¿é˜ˆå€¼åœ¨åˆç†èŒƒå›´å†…ï¼ˆ0.001-10 BTCï¼‰
            if self.config['big_trade_threshold'] > 10:
                logging.warning(f"âš ï¸ å¤§å•é˜ˆå€¼è¿‡é«˜ ({self.config['big_trade_threshold']} BTC)ï¼Œè°ƒæ•´ä¸º 0.05 BTC")
                self.config['big_trade_threshold'] = 0.05
            
            for trade in trades:
                qty = float(trade['qty'])
                if qty >= self.config['big_trade_threshold']:
                    big_trades.append({
                        'time': int(trade['time']),
                        'price': float(trade['price']),
                        'qty': qty,
                        'is_buyer_maker': trade['isBuyerMaker']
                    })
            
            if big_trades:
                logging.info(f"ğŸ“ˆ æ£€æµ‹åˆ° {len(big_trades)} ç¬”å¤§å•äº¤æ˜“ (>{self.config['big_trade_threshold']} BTC)")
            else:
                logging.info(f"ğŸ“Š æœªæ£€æµ‹åˆ°å¤§äº {self.config['big_trade_threshold']} BTC çš„å¤§å•äº¤æ˜“")
            
            return big_trades
        except Exception as e:
            logging.warning(f"è·å–äº¤æ˜“æ•°æ®å¤±è´¥: {e}")
            return []
    
    def get_order_book(self, symbol, limit=100):
        """è·å–è®¢å•ç°¿æ·±åº¦"""
        try:
            depth = self.client.get_order_book(symbol=symbol, limit=limit)
            
            # è®¡ç®—ä¹°å–ç›˜æ¯”ç‡
            bid_volume = sum([float(bid[1]) for bid in depth['bids'][:10]])
            ask_volume = sum([float(ask[1]) for ask in depth['asks'][:10]])
            ratio = bid_volume / ask_volume if ask_volume > 0 else 1
            
            logging.info(f"ğŸ“ˆ ä¹°å–ç›˜æ¯”ç‡: {ratio:.2f}")
            return depth
        except Exception as e:
            logging.warning(f"è·å–è®¢å•ç°¿å¤±è´¥: {e}")
            return {}
    
    def get_latest_price(self, symbol):
        """è·å–æœ€æ–°ä»·æ ¼"""
        try:
            ticker = self.client.get_symbol_ticker(symbol=symbol)
            return float(ticker['price'])
        except Exception as e:
            logging.error(f"è·å–ä»·æ ¼å¤±è´¥: {e}")
            return None

# å¢å¼ºçš„æ•°æ®å¤„ç†å™¨
class EnhancedDataProcessor:
    def __init__(self, config):
        self.config = config
        self.feature_scalers = {}
        self.label_processor = EnhancedLabelProcessor()
        self.sentiment_analyzer = None
        
        # åˆå§‹åŒ–featureså±æ€§ï¼Œé˜²æ­¢é¢„æµ‹æ—¶å‡ºé”™
        self.features = None
        
        # æ–°å¢æŠ€æœ¯æŒ‡æ ‡åˆ—è¡¨
        self.enhanced_indicators = [
            'rsi_14', 'rsi_21', 'macd', 'macd_signal', 'macd_histogram',
            'bb_upper', 'bb_middle', 'bb_lower', 'bb_pct',
            'sma_10', 'sma_20', 'ema_12', 'ema_26', 'adx',
            'stoch_k', 'stoch_d', 'cci', 'williams_r',
            'obv', 'atr', 'volume_sma', 'volume_ratio',
            'price_vs_sma20', 'ema_cross', 'momentum_5', 'momentum_10',
            'volatility_ratio', 'vwap', 'price_vs_vwap', 'high_low_pct',
            'rsi_smooth', 'volume_momentum', 'price_oscillation'
        ]
        
    def fetch_and_prepare_enhanced_data(self, api, retrain=False):
        """è·å–å¹¶å‡†å¤‡å¢å¼ºçš„æ•°æ®"""
        try:
            if self.sentiment_analyzer is None:
                self.sentiment_analyzer = MarketSentimentAnalyzer(api)
                
            # è·å–å¤šæ—¶é—´å‘¨æœŸæ•°æ®
            lookback_time = (datetime.now() - timedelta(hours=self.config['lookback_hours'])).strftime("%d %b, %Y")
            klines = api.get_multi_timeframe_data(self.config['symbol'], self.config['intervals'], lookback_time)
            
            if not klines:
                logging.error("âŒ æ— æ³•è·å–Kçº¿æ•°æ®")
                return None
            
            # å¤„ç†ä¸åŒæ—¶é—´å‘¨æœŸçš„æ•°æ®
            processed_data = {}
            for interval, kline_data in klines.items():
                df = self.process_klines_to_dataframe(kline_data, interval)
                if df is not None and not df.empty:
                    processed_data[interval] = df
                    logging.info(f"âœ… {interval}æ•°æ®å¤„ç†å®Œæˆ: {len(df)}æ¡è®°å½•")
            
            if not processed_data:
                logging.error("âŒ æ‰€æœ‰æ—¶é—´å‘¨æœŸæ•°æ®å¤„ç†å¤±è´¥")
                return None
            
            # è·å–å¸‚åœºæ·±åº¦å’Œå¤§å•æ•°æ®
            big_trades = []
            try:
                big_trades = api.get_recent_trades(self.config['symbol'])
            except Exception as e:
                logging.warning(f"âš ï¸ è·å–äº¤æ˜“æ•°æ®å¤±è´¥: {e}")
                big_trades = []
            
            market_depth = api.get_order_book(self.config['symbol'])
            
            # è·å–æƒ…ç»ªåˆ†ææ•°æ®
            sentiment_data = self.sentiment_analyzer.analyze_order_book_sentiment()
            
            # åˆå¹¶ç‰¹å¾
            combined_df = self.combine_timeframe_features(processed_data, big_trades, market_depth, sentiment_data)
            
            if combined_df is None or combined_df.empty:
                logging.error("âŒ ç‰¹å¾åˆå¹¶å¤±è´¥")
                return None
            
            if retrain:
                # åˆ›å»ºå¢å¼ºæ ‡ç­¾
                labels = self.label_processor.create_enhanced_labels(combined_df, self.config['prediction_minutes'])
                return self.prepare_training_data(combined_df, labels)
            else:
                return self.prepare_prediction_data(combined_df)
                
        except Exception as e:
            logging.error(f"âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
            return None
    
    def process_klines_to_dataframe(self, klines, interval):
        """å¤„ç†Kçº¿æ•°æ®ä¸ºDataFrame"""
        try:
            df = pd.DataFrame(klines, columns=[
                'open_time', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_asset_volume', 'number_of_trades',
                'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'
            ])
            
            # è½¬æ¢æ•°æ®ç±»å‹
            df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')
            numeric_columns = ['open', 'high', 'low', 'close', 'volume', 
                             'quote_asset_volume', 'number_of_trades',
                             'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']
            df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric)
            
            # æ·»åŠ æ—¶é—´å‘¨æœŸåç¼€
            price_columns = ['open', 'high', 'low', 'close', 'volume']
            for col in price_columns:
                df[f'{col}_{interval}'] = df[col]
            
            # åˆ›å»ºæŠ€æœ¯æŒ‡æ ‡
            df = self.add_enhanced_technical_indicators(df, interval)
            
            # ä¸¢å¼ƒNaNå€¼
            df.dropna(inplace=True)
            
            return df
        except Exception as e:
            logging.error(f"âŒ å¤„ç†{interval}æ•°æ®å¤±è´¥: {e}")
            return None
    
    def combine_timeframe_features(self, processed_data, big_trades, market_depth, sentiment_data):
        """åˆå¹¶å¤šæ—¶é—´å‘¨æœŸç‰¹å¾"""
        try:
            # ä»¥1åˆ†é’Ÿæ•°æ®ä¸ºåŸºå‡†
            base_df = processed_data.get('1m')
            if base_df is None:
                logging.error("âŒ ç¼ºå°‘1åˆ†é’ŸåŸºå‡†æ•°æ®")
                return None
            
            combined_df = base_df.copy()
            
            # æ·»åŠ å…¶ä»–æ—¶é—´å‘¨æœŸçš„å…³é”®æŒ‡æ ‡
            for interval in ['5m', '15m']:
                if interval in processed_data:
                    interval_df = processed_data[interval]
                    # é€šè¿‡æ—¶é—´å¯¹é½åˆå¹¶æ•°æ®
                    combined_df = self.merge_by_time(combined_df, interval_df, interval)
            
            # æ·»åŠ å¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾
            if big_trades:
                combined_df = self.add_big_trade_features(combined_df, big_trades)
            
            if market_depth:
                combined_df = self.add_market_depth_features(combined_df, market_depth)
            
            # æ·»åŠ æƒ…ç»ªåˆ†æç‰¹å¾
            if sentiment_data:
                combined_df = self.add_sentiment_features(combined_df, sentiment_data)
            
            return combined_df
        except Exception as e:
            logging.error(f"âŒ åˆå¹¶å¤šæ—¶é—´å‘¨æœŸç‰¹å¾å¤±è´¥: {e}")
            return None
    
    def merge_by_time(self, base_df, interval_df, interval):
        """é€šè¿‡æ—¶é—´å¯¹é½åˆå¹¶æ•°æ® - ğŸ”§ ä¼˜åŒ–æ€§èƒ½ï¼Œé¿å…DataFrameç¢ç‰‡åŒ–"""
        try:
            # ğŸ”§ è·å–æ‰€æœ‰éœ€è¦åˆå¹¶çš„ç‰¹å¾ï¼Œè€Œä¸åªæ˜¯é€‰æ‹©å‡ ä¸ªå…³é”®æŒ‡æ ‡
            exclude_cols = ['open_time', 'close_time']  # æ’é™¤æ—¶é—´åˆ—
            
            # é‡æ–°é‡‡æ ·åˆ°1åˆ†é’Ÿ
            interval_df_resampled = interval_df.set_index('open_time').resample('1min').ffill()
            
            # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šæ‰¹é‡å¤„ç†æ‰€æœ‰ç‰¹å¾ï¼Œé¿å…é€ä¸ªæ·»åŠ åˆ—
            new_columns = {}
            features_to_merge = [col for col in interval_df.columns if col not in exclude_cols and col != 'open_time']
            
            for col in features_to_merge:
                # ä¸ºæ‰€æœ‰ç‰¹å¾æ·»åŠ æ—¶é—´å‘¨æœŸåç¼€
                new_col_name = f"{col}_{interval}" if not col.endswith(f"_{interval}") else col
                
                # å°†ç‰¹å¾æ˜ å°„åˆ°åŸºå‡†æ•°æ®çš„æ—¶é—´ç´¢å¼•
                if col in interval_df_resampled.columns:
                    new_columns[new_col_name] = base_df['open_time'].map(
                        interval_df_resampled[col].to_dict()
                    )
            
            # ğŸ”§ ä¸€æ¬¡æ€§åˆå¹¶æ‰€æœ‰æ–°åˆ—ï¼Œé¿å…ç¢ç‰‡åŒ–
            if new_columns:
                new_df = pd.DataFrame(new_columns, index=base_df.index)
                base_df = pd.concat([base_df, new_df], axis=1)
            
            logging.info(f"ğŸ“Š æˆåŠŸåˆå¹¶{interval}æ—¶é—´å‘¨æœŸçš„{len(features_to_merge)}ä¸ªç‰¹å¾")
            return base_df
        except Exception as e:
            logging.error(f"âŒ æ—¶é—´å¯¹é½åˆå¹¶å¤±è´¥: {e}")
            return base_df
    
    def add_big_trade_features(self, df, big_trades):
        """æ·»åŠ å¤§å•ç‰¹å¾"""
        try:
            # è®¡ç®—æœ€è¿‘1åˆ†é’Ÿå†…çš„å¤§å•ç‰¹å¾
            current_time = time.time() * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            recent_big_trades = [t for t in big_trades 
                               if current_time - t['time'] <= 60000]  # 1åˆ†é’Ÿå†…
            
            df['big_trade_count'] = len(recent_big_trades)
            df['big_trade_volume'] = sum(t['qty'] for t in recent_big_trades)
            df['big_buy_ratio'] = (sum(t['qty'] for t in recent_big_trades if not t['is_buyer_maker']) / 
                                 max(1, sum(t['qty'] for t in recent_big_trades)))
            
            # ä½¿ç”¨ä¸get_recent_tradesç›¸åŒçš„æ ¼å¼æ˜¾ç¤ºå¤§å•ä¿¡æ¯
            threshold = self.config.get('big_trade_threshold', 0.01)
            if recent_big_trades:
                logging.info(f"ğŸ’° æ£€æµ‹åˆ° {len(recent_big_trades)} ç¬”æœ€è¿‘1åˆ†é’Ÿå†…çš„å¤§å•äº¤æ˜“ (>{threshold} BTC)")
            else:
                logging.info(f"ğŸ’° æœ€è¿‘1åˆ†é’Ÿå†…æ— å¤§å•äº¤æ˜“ (>{threshold} BTC)")
                
            return df
        except Exception as e:
            logging.error(f"âŒ æ·»åŠ å¤§å•ç‰¹å¾å¤±è´¥: {e}")
            return df
    
    def add_market_depth_features(self, df, market_depth):
        """æ·»åŠ å¸‚åœºæ·±åº¦ç‰¹å¾ - ğŸ”§ ä¼˜åŒ–æ€§èƒ½"""
        try:
            if not market_depth or 'bids' not in market_depth or 'asks' not in market_depth:
                # å¦‚æœæ²¡æœ‰å¸‚åœºæ·±åº¦æ•°æ®ï¼Œæ‰¹é‡å¡«å……é»˜è®¤å€¼
                default_depth_features = {
                    'bid_ask_spread': 0,
                    'depth_ratio': 1.0,
                    'price_impact': 0
                }
                for key, value in default_depth_features.items():
                    df[key] = value
                return df
            
            bids = market_depth['bids']
            asks = market_depth['asks']
            
            if not bids or not asks:
                default_depth_features = {
                    'bid_ask_spread': 0,
                    'depth_ratio': 1.0,
                    'price_impact': 0
                }
                for key, value in default_depth_features.items():
                    df[key] = value
                return df
            
            # ä¹°å–ä»·å·®
            best_bid = float(bids[0][0])
            best_ask = float(asks[0][0])
            spread = (best_ask - best_bid) / best_bid * 100
            
            # æ·±åº¦æ¯”ç‡
            bid_volume = sum([float(bid[1]) for bid in bids[:5]])
            ask_volume = sum([float(ask[1]) for ask in asks[:5]])
            depth_ratio = bid_volume / ask_volume if ask_volume > 0 else 1
            
            # ä»·æ ¼å†²å‡»ï¼ˆ5ä¸‡USDTæˆäº¤çš„ä»·æ ¼å½±å“ï¼‰
            target_volume = 50000
            cumulative_volume = 0
            price_impact = 0
            
            for ask in asks:
                price = float(ask[0])
                volume = float(ask[1])
                if cumulative_volume + volume * price >= target_volume:
                    price_impact = (price - best_ask) / best_ask * 100
                    break
                cumulative_volume += volume * price
            
            # ğŸ”§ æ‰¹é‡æ·»åŠ æ‰€æœ‰å¸‚åœºæ·±åº¦ç‰¹å¾
            depth_features = {
                'bid_ask_spread': spread,
                'depth_ratio': depth_ratio,
                'price_impact': price_impact
            }
            for key, value in depth_features.items():
                df[key] = value
            
            return df
        except Exception as e:
            logging.warning(f"âš ï¸ æ·»åŠ å¸‚åœºæ·±åº¦ç‰¹å¾å¤±è´¥: {e}")
            # æ‰¹é‡æ·»åŠ é»˜è®¤å€¼
            default_depth_features = {
                'bid_ask_spread': 0,
                'depth_ratio': 1.0,
                'price_impact': 0
            }
            for key, value in default_depth_features.items():
                df[key] = value
            return df
    
    def add_sentiment_features(self, df, sentiment_data):
        """æ·»åŠ æƒ…ç»ªç‰¹å¾ - ğŸ”§ æ”¯æŒå¢å¼ºçš„æƒ…ç»ªæŒ‡æ ‡ï¼Œä¼˜åŒ–æ€§èƒ½"""
        try:
            # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šæ‰¹é‡æ·»åŠ æ‰€æœ‰æƒ…ç»ªç‰¹å¾
            sentiment_features = {
                # åŸºç¡€æƒ…ç»ªç‰¹å¾
                'sentiment_score': sentiment_data.get('sentiment_score', 0.5),
                'book_imbalance': sentiment_data.get('book_imbalance', 0),
                'bid_ask_ratio': sentiment_data.get('bid_volume', 0) / max(sentiment_data.get('ask_volume', 1), 1),
                
                # ğŸ”§ æ–°å¢ï¼šä¹°å¢™/å–å¢™ç‰¹å¾
                'buy_wall_volume': sentiment_data.get('buy_wall_volume', 0),
                'sell_wall_volume': sentiment_data.get('sell_wall_volume', 0),
                'wall_ratio': sentiment_data.get('wall_ratio', 1.0),
                'deep_imbalance': sentiment_data.get('deep_imbalance', 0),
                
                # ğŸ”§ æ–°å¢ï¼šæƒ…ç»ªå¼ºåº¦æŒ‡æ ‡
                'sentiment_strength': abs(sentiment_data.get('sentiment_score', 0.5) - 0.5) * 2,  # 0-1
                'wall_dominance': 1 if sentiment_data.get('wall_ratio', 1.0) > 1.2 else (-1 if sentiment_data.get('wall_ratio', 1.0) < 0.8 else 0)
            }
            
            # ğŸ”§ ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰æƒ…ç»ªç‰¹å¾
            for key, value in sentiment_features.items():
                df[key] = value
            
            return df
        except Exception as e:
            logging.warning(f"âš ï¸ æ·»åŠ æƒ…ç»ªç‰¹å¾å¤±è´¥: {e}")
            # æ·»åŠ é»˜è®¤å€¼
            default_features = {
                'sentiment_score': 0.5,
                'book_imbalance': 0,
                'bid_ask_ratio': 1.0,
                'buy_wall_volume': 0,
                'sell_wall_volume': 0,
                'wall_ratio': 1.0,
                'deep_imbalance': 0,
                'sentiment_strength': 0,
                'wall_dominance': 0
            }
            for key, value in default_features.items():
                df[key] = value
            return df
    
    def prepare_training_data(self, df, labels):
        """å‡†å¤‡è®­ç»ƒæ•°æ® - æ”¯æŒå¤šæ ‡ç­¾"""
        try:
            # ğŸ”§ ä¼˜åŒ–ç‰¹å¾é€‰æ‹© - ç¡®ä¿æ‰€æœ‰ç‰¹å¾éƒ½åŒ…å«
            feature_cols = []
            
            # åŸºç¡€ä»·æ ¼ç‰¹å¾
            base_cols = ['open', 'high', 'low', 'close', 'volume']
            for col in base_cols:
                if col in df.columns:
                    feature_cols.append(col)
            
            # ğŸ”§ æ”¶é›†æ‰€æœ‰æ—¶é—´å‘¨æœŸçš„æŠ€æœ¯æŒ‡æ ‡
            intervals = ['1m', '5m', '15m']
            tech_indicators = [
                'rsi_7', 'rsi_14',  # ğŸ”§ åŒ…å«rsi_7ï¼ˆæ–°å¢ï¼‰å’Œrsi_14
                'ema_fast', 'ema_slow', 'macd_simple', 'macd_signal',  # ğŸ”§ ä½¿ç”¨æ–°çš„EMAå’ŒMACD
                'macd', 'macd_histogram',
                'sma_5', 'sma_10', 'sma_20', 'ema_12', 'ema_26',  # ğŸ”§ åŒ…å«sma_5
                'adx', 'stoch_k', 'stoch_d', 'cci', 'williams_r',
                'bb_upper', 'bb_middle', 'bb_lower', 'bb_pct',
                'atr', 'obv', 'volume_sma', 'volume_ratio',
                'price_vs_sma10', 'price_vs_sma20', 'ema_cross',  # ğŸ”§ åŒ…å«price_vs_sma10
                'momentum_3', 'momentum_5', 'momentum_10',  # ğŸ”§ åŒ…å«momentum_3
                'volatility_ratio', 'vwap', 'price_vs_vwap',
                'high_low_pct', 'rsi_smooth', 'volume_momentum',
                'price_oscillation', 'trend_fast', 'trend_strength'  # ğŸ”§ åŒ…å«æ–°æŒ‡æ ‡
            ]
            
            # ğŸ”§ åŠ¨æ€æ·»åŠ æ‰€æœ‰å¯ç”¨çš„æŠ€æœ¯æŒ‡æ ‡
            missing_tech_features = {}  # ğŸ”§ æ‰¹é‡æ”¶é›†ç¼ºå¤±çš„æŠ€æœ¯æŒ‡æ ‡
            
            for interval in intervals:
                for indicator in tech_indicators:
                    col_name = f"{indicator}_{interval}"
                    if col_name in df.columns:
                        feature_cols.append(col_name)
                    else:
                        # ğŸ”§ å¦‚æœç¼ºå¤±æŠ€æœ¯æŒ‡æ ‡ï¼Œæ·»åŠ é»˜è®¤å€¼è€Œä¸æ˜¯è·³è¿‡
                        missing_features = getattr(self, '_missing_features', set())
                        if col_name not in missing_features:
                            logging.warning(f"âš ï¸ ç¼ºå°‘ç‰¹å¾: {col_name}")
                            missing_features.add(col_name)
                            self._missing_features = missing_features
                        
                        # ğŸ”§ ä¸ºç¼ºå¤±çš„æŠ€æœ¯æŒ‡æ ‡æ”¶é›†åˆç†çš„é»˜è®¤å€¼
                        if 'rsi' in indicator:
                            missing_tech_features[col_name] = 50  # RSIä¸­ä½å€¼
                        elif 'macd' in indicator:
                            missing_tech_features[col_name] = 0   # MACDä¸­æ€§å€¼
                        elif 'ema' in indicator or 'sma' in indicator or 'bb_' in indicator or 'vwap' in indicator:
                            missing_tech_features[col_name] = df['close']  # ä½¿ç”¨å½“å‰ä»·æ ¼ä½œä¸ºé»˜è®¤å€¼
                        elif 'stoch' in indicator:
                            missing_tech_features[col_name] = 50  # éšæœºæŒ¯è¡å™¨ä¸­ä½å€¼
                        elif 'adx' in indicator:
                            missing_tech_features[col_name] = 25  # ADXä¸­ç­‰å¼ºåº¦
                        elif 'cci' in indicator:
                            missing_tech_features[col_name] = 0   # CCIä¸­æ€§å€¼
                        elif 'williams_r' in indicator:
                            missing_tech_features[col_name] = -50 # Williams %Rä¸­ä½å€¼
                        elif 'atr' in indicator:
                            missing_tech_features[col_name] = (df['high'] - df['low']).mean()  # ä½¿ç”¨å¹³å‡æ³¢å¹…
                        elif 'volume' in indicator:
                            missing_tech_features[col_name] = df['volume'].mean()  # ä½¿ç”¨å¹³å‡æˆäº¤é‡
                        elif 'momentum' in indicator:
                            missing_tech_features[col_name] = 0   # åŠ¨é‡ä¸­æ€§å€¼
                        elif 'volatility' in indicator:
                            missing_tech_features[col_name] = 1   # æ³¢åŠ¨ç‡æ¯”ç‡ä¸­æ€§å€¼
                        elif 'trend' in indicator:
                            missing_tech_features[col_name] = 0.5 # è¶‹åŠ¿ä¸­æ€§å€¼
                        elif indicator in ['ema_cross', 'trend_fast']:
                            missing_tech_features[col_name] = 0   # äºŒå…ƒæŒ‡æ ‡é»˜è®¤å€¼
                        else:
                            missing_tech_features[col_name] = 0   # å…¶ä»–æŒ‡æ ‡é»˜è®¤å€¼
                        
                        feature_cols.append(col_name)
            
            # ğŸ”§ æ‰¹é‡æ·»åŠ æ‰€æœ‰ç¼ºå¤±çš„æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
            if missing_tech_features:
                for col_name, default_value in missing_tech_features.items():
                    df[col_name] = default_value
            
            # ğŸ”§ æƒ…ç»ªç‰¹å¾ - åŒ…å«æ‰€æœ‰æ–°å¢çš„æƒ…ç»ªæŒ‡æ ‡
            sentiment_cols = [
                'sentiment_score', 'book_imbalance', 'bid_ask_ratio',
                'buy_wall_volume', 'sell_wall_volume', 'wall_ratio', 'deep_imbalance',
                'sentiment_strength', 'wall_dominance'
            ]
            for col in sentiment_cols:
                if col in df.columns:
                    feature_cols.append(col)
                else:
                    # ğŸ”§ å¦‚æœç¼ºå¤±æƒ…ç»ªç‰¹å¾ï¼Œæ·»åŠ é»˜è®¤å€¼
                    if col == 'sentiment_score':
                        df[col] = 0.5
                    elif col in ['buy_wall_volume', 'sell_wall_volume', 'book_imbalance', 'deep_imbalance']:
                        df[col] = 0
                    elif col == 'bid_ask_ratio' or col == 'wall_ratio':
                        df[col] = 1.0
                    elif col == 'sentiment_strength':
                        df[col] = 0
                    elif col == 'wall_dominance':
                        df[col] = 0
                    feature_cols.append(col)
            
            # ğŸ”§ å¸‚åœºæ·±åº¦ç‰¹å¾
            depth_cols = ['bid_ask_spread', 'depth_ratio', 'price_impact']
            for col in depth_cols:
                if col in df.columns:
                    feature_cols.append(col)
                else:
                    # ğŸ”§ å¦‚æœç¼ºå¤±æ·±åº¦ç‰¹å¾ï¼Œæ·»åŠ é»˜è®¤å€¼
                    if col == 'bid_ask_spread' or col == 'price_impact':
                        df[col] = 0
                    elif col == 'depth_ratio':
                        df[col] = 1.0
                    feature_cols.append(col)
            
            # ğŸ”§ å¤§å•ç‰¹å¾
            trade_cols = ['big_trade_count', 'big_trade_volume', 'big_buy_ratio']
            for col in trade_cols:
                if col in df.columns:
                    feature_cols.append(col)
                else:
                    # ğŸ”§ å¦‚æœç¼ºå¤±å¤§å•ç‰¹å¾ï¼Œæ·»åŠ é»˜è®¤å€¼
                    if col == 'big_trade_count' or col == 'big_trade_volume':
                        df[col] = 0
                    elif col == 'big_buy_ratio':
                        df[col] = 0.5
                    feature_cols.append(col)
            
            if not feature_cols:
                logging.error("âŒ æ²¡æœ‰å¯ç”¨çš„ç‰¹å¾åˆ—")
                return None
            
            # ç‰¹å¾æ•°æ®
            feature_data = df[feature_cols].dropna()
            
            if len(feature_data) < 50:
                logging.error("âŒ ç‰¹å¾æ•°æ®ä¸è¶³")
                return None
            
            # ä¿å­˜ç‰¹å¾åˆ—å
            self.features = feature_cols
            
            # ç‰¹å¾ç¼©æ”¾
            if '1m' not in self.feature_scalers:
                self.feature_scalers['1m'] = MinMaxScaler()
                scaled_features = self.feature_scalers['1m'].fit_transform(feature_data)
            else:
                scaled_features = self.feature_scalers['1m'].transform(feature_data)
            
            # åˆ›å»ºåºåˆ—æ•°æ® - åªä½¿ç”¨åŸºç¡€æ–¹å‘æ ‡ç­¾è¿›è¡Œå…¼å®¹
            X, y = self.create_sequences(scaled_features, labels['direction'].loc[feature_data.index].values)
            
            return X, y
            
        except Exception as e:
            logging.error(f"âŒ å‡†å¤‡è®­ç»ƒæ•°æ®æ—¶å‡ºé”™: {e}")
            return None
    
    def prepare_prediction_data(self, df):
        """å‡†å¤‡é¢„æµ‹æ•°æ® - ğŸ”§ ç¡®ä¿ç‰¹å¾ä¸€è‡´æ€§"""
        try:
            # ğŸ”§ ä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„ç‰¹å¾é€‰æ‹©é€»è¾‘
            feature_cols = []
            
            # åŸºç¡€ä»·æ ¼ç‰¹å¾
            base_cols = ['open', 'high', 'low', 'close', 'volume']
            for col in base_cols:
                if col in df.columns:
                    feature_cols.append(col)
            
            # ğŸ”§ æ”¶é›†æ‰€æœ‰æ—¶é—´å‘¨æœŸçš„æŠ€æœ¯æŒ‡æ ‡ï¼ˆä¸è®­ç»ƒæ—¶ç›¸åŒï¼‰
            intervals = ['1m', '5m', '15m']
            tech_indicators = [
                'rsi_7', 'rsi_14',  # ğŸ”§ åŒ…å«rsi_7ï¼ˆæ–°å¢ï¼‰å’Œrsi_14
                'ema_fast', 'ema_slow', 'macd_simple', 'macd_signal',  # ğŸ”§ ä½¿ç”¨æ–°çš„EMAå’ŒMACD
                'macd', 'macd_histogram',
                'sma_5', 'sma_10', 'sma_20', 'ema_12', 'ema_26',  # ğŸ”§ åŒ…å«sma_5
                'adx', 'stoch_k', 'stoch_d', 'cci', 'williams_r',
                'bb_upper', 'bb_middle', 'bb_lower', 'bb_pct',
                'atr', 'obv', 'volume_sma', 'volume_ratio',
                'price_vs_sma10', 'price_vs_sma20', 'ema_cross',  # ğŸ”§ åŒ…å«price_vs_sma10
                'momentum_3', 'momentum_5', 'momentum_10',  # ğŸ”§ åŒ…å«momentum_3
                'volatility_ratio', 'vwap', 'price_vs_vwap',
                'high_low_pct', 'rsi_smooth', 'volume_momentum',
                'price_oscillation', 'trend_fast', 'trend_strength'  # ğŸ”§ åŒ…å«æ–°æŒ‡æ ‡
            ]
            
            # ğŸ”§ åŠ¨æ€æ·»åŠ æ‰€æœ‰å¯ç”¨çš„æŠ€æœ¯æŒ‡æ ‡
            missing_tech_features = {}  # ğŸ”§ æ‰¹é‡æ”¶é›†ç¼ºå¤±çš„æŠ€æœ¯æŒ‡æ ‡
            
            for interval in intervals:
                for indicator in tech_indicators:
                    col_name = f"{indicator}_{interval}"
                    if col_name in df.columns:
                        feature_cols.append(col_name)
                    else:
                        # ğŸ”§ å¦‚æœç¼ºå¤±æŠ€æœ¯æŒ‡æ ‡ï¼Œæ·»åŠ é»˜è®¤å€¼è€Œä¸æ˜¯è·³è¿‡
                        missing_features = getattr(self, '_missing_features', set())
                        if col_name not in missing_features:
                            logging.warning(f"âš ï¸ ç¼ºå°‘ç‰¹å¾: {col_name}")
                            missing_features.add(col_name)
                            self._missing_features = missing_features
                        
                        # ğŸ”§ ä¸ºç¼ºå¤±çš„æŠ€æœ¯æŒ‡æ ‡æ”¶é›†åˆç†çš„é»˜è®¤å€¼
                        if 'rsi' in indicator:
                            missing_tech_features[col_name] = 50  # RSIä¸­ä½å€¼
                        elif 'macd' in indicator:
                            missing_tech_features[col_name] = 0   # MACDä¸­æ€§å€¼
                        elif 'ema' in indicator or 'sma' in indicator or 'bb_' in indicator or 'vwap' in indicator:
                            missing_tech_features[col_name] = df['close']  # ä½¿ç”¨å½“å‰ä»·æ ¼ä½œä¸ºé»˜è®¤å€¼
                        elif 'stoch' in indicator:
                            missing_tech_features[col_name] = 50  # éšæœºæŒ¯è¡å™¨ä¸­ä½å€¼
                        elif 'adx' in indicator:
                            missing_tech_features[col_name] = 25  # ADXä¸­ç­‰å¼ºåº¦
                        elif 'cci' in indicator:
                            missing_tech_features[col_name] = 0   # CCIä¸­æ€§å€¼
                        elif 'williams_r' in indicator:
                            missing_tech_features[col_name] = -50 # Williams %Rä¸­ä½å€¼
                        elif 'atr' in indicator:
                            missing_tech_features[col_name] = (df['high'] - df['low']).mean()  # ä½¿ç”¨å¹³å‡æ³¢å¹…
                        elif 'volume' in indicator:
                            missing_tech_features[col_name] = df['volume'].mean()  # ä½¿ç”¨å¹³å‡æˆäº¤é‡
                        elif 'momentum' in indicator:
                            missing_tech_features[col_name] = 0   # åŠ¨é‡ä¸­æ€§å€¼
                        elif 'volatility' in indicator:
                            missing_tech_features[col_name] = 1   # æ³¢åŠ¨ç‡æ¯”ç‡ä¸­æ€§å€¼
                        elif 'trend' in indicator:
                            missing_tech_features[col_name] = 0.5 # è¶‹åŠ¿ä¸­æ€§å€¼
                        elif indicator in ['ema_cross', 'trend_fast']:
                            missing_tech_features[col_name] = 0   # äºŒå…ƒæŒ‡æ ‡é»˜è®¤å€¼
                        else:
                            missing_tech_features[col_name] = 0   # å…¶ä»–æŒ‡æ ‡é»˜è®¤å€¼
                        
                        feature_cols.append(col_name)
            
            # ğŸ”§ æ‰¹é‡æ·»åŠ æ‰€æœ‰ç¼ºå¤±çš„æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
            if missing_tech_features:
                for col_name, default_value in missing_tech_features.items():
                    df[col_name] = default_value
            
            # ğŸ”§ æƒ…ç»ªç‰¹å¾ - åŒ…å«æ‰€æœ‰æ–°å¢çš„æƒ…ç»ªæŒ‡æ ‡
            sentiment_cols = [
                'sentiment_score', 'book_imbalance', 'bid_ask_ratio',
                'buy_wall_volume', 'sell_wall_volume', 'wall_ratio', 'deep_imbalance',
                'sentiment_strength', 'wall_dominance'
            ]
            for col in sentiment_cols:
                if col in df.columns:
                    feature_cols.append(col)
                else:
                    # ğŸ”§ å¦‚æœç¼ºå¤±æƒ…ç»ªç‰¹å¾ï¼Œæ·»åŠ é»˜è®¤å€¼
                    if col == 'sentiment_score':
                        df[col] = 0.5
                    elif col in ['buy_wall_volume', 'sell_wall_volume', 'book_imbalance', 'deep_imbalance']:
                        df[col] = 0
                    elif col == 'bid_ask_ratio' or col == 'wall_ratio':
                        df[col] = 1.0
                    elif col == 'sentiment_strength':
                        df[col] = 0
                    elif col == 'wall_dominance':
                        df[col] = 0
                    feature_cols.append(col)
            
            # ğŸ”§ å¸‚åœºæ·±åº¦ç‰¹å¾
            depth_cols = ['bid_ask_spread', 'depth_ratio', 'price_impact']
            for col in depth_cols:
                if col in df.columns:
                    feature_cols.append(col)
                else:
                    # ğŸ”§ å¦‚æœç¼ºå¤±æ·±åº¦ç‰¹å¾ï¼Œæ·»åŠ é»˜è®¤å€¼
                    if col == 'bid_ask_spread' or col == 'price_impact':
                        df[col] = 0
                    elif col == 'depth_ratio':
                        df[col] = 1.0
                    feature_cols.append(col)
            
            # ğŸ”§ å¤§å•ç‰¹å¾
            trade_cols = ['big_trade_count', 'big_trade_volume', 'big_buy_ratio']
            for col in trade_cols:
                if col in df.columns:
                    feature_cols.append(col)
                else:
                    # ğŸ”§ å¦‚æœç¼ºå¤±å¤§å•ç‰¹å¾ï¼Œæ·»åŠ é»˜è®¤å€¼
                    if col == 'big_trade_count' or col == 'big_trade_volume':
                        df[col] = 0
                    elif col == 'big_buy_ratio':
                        df[col] = 0.5
                    feature_cols.append(col)
            
            if not feature_cols:
                logging.error("âŒ æ²¡æœ‰å¯ç”¨çš„ç‰¹å¾åˆ—")
                return None, None
            
            # ğŸ”§ é”™è¯¯æ—¥å¿—ï¼šæ˜¾ç¤ºæœ€ç»ˆä½¿ç”¨çš„ç‰¹å¾
            logging.info(f"âœ… é¢„æµ‹ç‰¹å¾æ•°é‡: {len(feature_cols)}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±çš„å…³é”®ç‰¹å¾
            missing_key_features = []
            key_features = ['rsi_14_1m', 'close', 'volume']
            for key_feature in key_features:
                if key_feature not in feature_cols:
                    missing_key_features.append(key_feature)
            
            if missing_key_features:
                logging.error(f"âŒ ç¼ºå°‘å…³é”®ç‰¹å¾: {missing_key_features}")
                return None, None
            
            # é€‰æ‹©ç‰¹å¾æ•°æ®
            feature_data = df[feature_cols].copy()
            
            # ğŸ”§ ä¼˜åŒ–NaNå¤„ç†
            # é¦–å…ˆæ£€æŸ¥NaNæƒ…å†µ
            nan_counts = feature_data.isnull().sum()
            total_nans = nan_counts.sum()
            if total_nans > 0:
                logging.info(f"ğŸ“Š æ£€æµ‹åˆ° {total_nans} ä¸ªNaNå€¼ï¼Œè¿›è¡Œå¤„ç†...")
                
                # ğŸ”§ ä¿®å¤FutureWarningï¼šä½¿ç”¨æ–°çš„æ–¹æ³•æ›¿ä»£è¿‡æ—¶çš„methodå‚æ•°
                feature_data = feature_data.ffill().bfill().fillna(0)
                
                # å†æ¬¡æ£€æŸ¥
                remaining_nans = feature_data.isnull().sum().sum()
                if remaining_nans > 0:
                    logging.warning(f"âš ï¸ ä»æœ‰ {remaining_nans} ä¸ªNaNå€¼ï¼Œä½¿ç”¨å‡å€¼å¡«å……")
                    feature_data = feature_data.fillna(feature_data.mean()).fillna(0)
            
            # ç‰¹å¾ç¼©æ”¾
            if hasattr(self, 'feature_scalers') and self.feature_scalers:
                try:
                    # ğŸ”§ ä¿®å¤ï¼šä»å­—å…¸ä¸­è·å–æ­£ç¡®çš„ç¼©æ”¾å™¨
                    if '1m' in self.feature_scalers:
                        feature_data_scaled = self.feature_scalers['1m'].transform(feature_data)
                    elif isinstance(self.feature_scalers, dict) and len(self.feature_scalers) > 0:
                        # å¦‚æœæ²¡æœ‰'1m'é”®ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„ç¼©æ”¾å™¨
                        scaler_key = list(self.feature_scalers.keys())[0]
                        feature_data_scaled = self.feature_scalers[scaler_key].transform(feature_data)
                    else:
                        # å…¼å®¹æ—§ç‰ˆæœ¬ï¼šå¦‚æœfeature_scalersæœ¬èº«å°±æ˜¯ç¼©æ”¾å™¨å¯¹è±¡
                        feature_data_scaled = self.feature_scalers.transform(feature_data)
                except Exception as e:
                    logging.error(f"âŒ ç‰¹å¾ç¼©æ”¾å¤±è´¥: {e}")
                    return None, None
            else:
                logging.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç‰¹å¾ç¼©æ”¾å™¨ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
                feature_data_scaled = feature_data.values
            
            # åˆ›å»ºæ—¶é—´åºåˆ—
            sequence_length = self.config.get('sequence_length', 10)
            if len(feature_data_scaled) < sequence_length:
                logging.error(f"âŒ æ•°æ®é•¿åº¦ä¸è¶³ï¼šéœ€è¦{sequence_length}ï¼Œå®é™…{len(feature_data_scaled)}")
                return None, None
            
            # å–æœ€åsequence_lengthä¸ªæ—¶é—´æ­¥
            X = feature_data_scaled[-sequence_length:].reshape(1, sequence_length, -1)
            
            return X, df
            
        except Exception as e:
            logging.error(f"âŒ å‡†å¤‡é¢„æµ‹æ•°æ®å¤±è´¥: {e}")
            return None, None
    
    def add_enhanced_technical_indicators(self, df, interval):
        """æ·»åŠ å¢å¼ºçš„æŠ€æœ¯æŒ‡æ ‡ - ğŸ”§ ä¼˜åŒ–ä»¥å‡å°‘NaNå€¼"""
        try:
            suffix = f"_{interval}"
            
            # ğŸ”µ 1. è¶‹åŠ¿æŒ‡æ ‡ - ğŸ”§ ä¼˜åŒ–è®¡ç®—çª—å£
            # RSI (ä½¿ç”¨è¾ƒçŸ­çª—å£å‡å°‘NaN)
            df[f'rsi_7{suffix}'] = ta.momentum.rsi(df['close'], window=7)  # ğŸ”§ ä»14æ”¹ä¸º7
            df[f'rsi_14{suffix}'] = ta.momentum.rsi(df['close'], window=14)
            
            # ğŸ”§ EMAæ›¿ä»£MACDå‡å°‘NaN - ä½¿ç”¨æ›´çŸ­çª—å£
            # å¿«é€ŸEMAå’Œæ…¢é€ŸEMA
            df[f'ema_fast{suffix}'] = ta.trend.ema_indicator(df['close'], window=8)  # ğŸ”§ ä»12æ”¹ä¸º8
            df[f'ema_slow{suffix}'] = ta.trend.ema_indicator(df['close'], window=21)  # ğŸ”§ ä»26æ”¹ä¸º21
            
            # ç®€åŒ–çš„MACDä¿¡å·
            df[f'macd_simple{suffix}'] = df[f'ema_fast{suffix}'] - df[f'ema_slow{suffix}']
            df[f'macd_signal{suffix}'] = ta.trend.ema_indicator(df[f'macd_simple{suffix}'], window=6)  # ğŸ”§ ä»9æ”¹ä¸º6
            
            # ä¿ç•™åŸå§‹MACDç”¨äºå…¼å®¹æ€§ï¼ˆä½†ä½¿ç”¨æ›´çŸ­çª—å£ï¼‰
            try:
                macd = ta.trend.MACD(df['close'], window_slow=21, window_fast=8, window_sign=6)  # ğŸ”§ ä¼˜åŒ–çª—å£
                df[f'macd{suffix}'] = macd.macd()
                df[f'macd_histogram{suffix}'] = macd.macd_diff()
            except:
                # å¦‚æœMACDè®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
                df[f'macd{suffix}'] = df[f'macd_simple{suffix}']
                df[f'macd_histogram{suffix}'] = df[f'macd_simple{suffix}'] - df[f'macd_signal{suffix}']
            
            # ç§»åŠ¨å¹³å‡çº¿ - ğŸ”§ ä½¿ç”¨æ›´çŸ­çª—å£
            df[f'sma_5{suffix}'] = ta.trend.sma_indicator(df['close'], window=5)   # ğŸ”§ æ–°å¢çŸ­æœŸSMA
            df[f'sma_10{suffix}'] = ta.trend.sma_indicator(df['close'], window=10)
            df[f'sma_20{suffix}'] = ta.trend.sma_indicator(df['close'], window=20)
            df[f'ema_12{suffix}'] = ta.trend.ema_indicator(df['close'], window=12)
            df[f'ema_26{suffix}'] = ta.trend.ema_indicator(df['close'], window=26)
            
            # ADX (å¹³å‡æ–¹å‘æŒ‡æ•°) - ğŸ”§ ä½¿ç”¨æ›´çŸ­çª—å£
            try:
                df[f'adx{suffix}'] = ta.trend.adx(df['high'], df['low'], df['close'], window=10)  # ğŸ”§ ä»14æ”¹ä¸º10
            except:
                df[f'adx{suffix}'] = 50  # é»˜è®¤ä¸­æ€§å€¼
            
            # ğŸ”µ 2. åŠ¨é‡æŒ‡æ ‡ - ğŸ”§ ä¼˜åŒ–çª—å£å¤§å°
            # éšæœºæŒ¯è¡å™¨ - ä½¿ç”¨æ›´çŸ­çª—å£
            try:
                stoch = ta.momentum.StochasticOscillator(df['high'], df['low'], df['close'], window=10, smooth_window=3)  # ğŸ”§ ä¼˜åŒ–çª—å£
                df[f'stoch_k{suffix}'] = stoch.stoch()
                df[f'stoch_d{suffix}'] = stoch.stoch_signal()
            except:
                df[f'stoch_k{suffix}'] = 50
                df[f'stoch_d{suffix}'] = 50
            
            # CCI (å•†å“é¢‘é“æŒ‡æ ‡) - ğŸ”§ ä½¿ç”¨æ›´çŸ­çª—å£
            try:
                df[f'cci{suffix}'] = ta.trend.cci(df['high'], df['low'], df['close'], window=14)  # ğŸ”§ ä»20æ”¹ä¸º14
            except:
                df[f'cci{suffix}'] = 0
            
            # Williams %R - ğŸ”§ ä½¿ç”¨æ›´çŸ­çª—å£
            try:
                df[f'williams_r{suffix}'] = ta.momentum.williams_r(df['high'], df['low'], df['close'], lbp=10)  # ğŸ”§ ä»14æ”¹ä¸º10
            except:
                df[f'williams_r{suffix}'] = -50
            
            # ğŸ”µ 3. æ³¢åŠ¨ç‡æŒ‡æ ‡ - ğŸ”§ ä¼˜åŒ–çª—å£
            # å¸ƒæ—å¸¦ - ä½¿ç”¨æ›´çŸ­çª—å£
            try:
                bollinger = ta.volatility.BollingerBands(df['close'], window=15, window_dev=2)  # ğŸ”§ ä»20æ”¹ä¸º15
                df[f'bb_upper{suffix}'] = bollinger.bollinger_hband()
                df[f'bb_middle{suffix}'] = bollinger.bollinger_mavg()
                df[f'bb_lower{suffix}'] = bollinger.bollinger_lband()
                df[f'bb_pct{suffix}'] = bollinger.bollinger_pband()
            except:
                # å¦‚æœå¸ƒæ—å¸¦è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
                sma_15 = df['close'].rolling(15).mean()
                std_15 = df['close'].rolling(15).std()
                df[f'bb_upper{suffix}'] = sma_15 + 2 * std_15
                df[f'bb_middle{suffix}'] = sma_15
                df[f'bb_lower{suffix}'] = sma_15 - 2 * std_15
                df[f'bb_pct{suffix}'] = (df['close'] - df[f'bb_lower{suffix}']) / (df[f'bb_upper{suffix}'] - df[f'bb_lower{suffix}'])
            
            # ATR (å¹³å‡çœŸå®æ³¢å¹…) - ğŸ”§ ä½¿ç”¨æ›´çŸ­çª—å£
            try:
                df[f'atr{suffix}'] = ta.volatility.average_true_range(df['high'], df['low'], df['close'], window=10)  # ğŸ”§ ä»14æ”¹ä¸º10
            except:
                df[f'atr{suffix}'] = (df['high'] - df['low']).rolling(10).mean()
            
            # ğŸ”µ 4. æˆäº¤é‡æŒ‡æ ‡
            # OBV (èƒ½é‡æ½®)
            try:
                df[f'obv{suffix}'] = ta.volume.on_balance_volume(df['close'], df['volume'])
            except:
                df[f'obv{suffix}'] = df['volume'].cumsum()
            
            # æˆäº¤é‡å‡çº¿å’Œæ¯”ç‡ - ğŸ”§ ä½¿ç”¨æ›´çŸ­çª—å£
            df[f'volume_sma{suffix}'] = ta.trend.sma_indicator(df['volume'], window=10)  # ğŸ”§ ä»20æ”¹ä¸º10
            df[f'volume_ratio{suffix}'] = df['volume'] / df[f'volume_sma{suffix}'].replace(0, 1)
            
            # ğŸ”µ 5. è‡ªå®šä¹‰æŒ‡æ ‡ (é¿å…è¿‡æ‹Ÿåˆ) - ğŸ”§ ä¼˜åŒ–è®¡ç®—
            # ä»·æ ¼ç›¸å¯¹ä½ç½®
            df[f'price_vs_sma10{suffix}'] = (df['close'] - df[f'sma_10{suffix}']) / df[f'sma_10{suffix}'].replace(0, 1) * 100  # ğŸ”§ ä½¿ç”¨SMA10
            df[f'price_vs_sma20{suffix}'] = (df['close'] - df[f'sma_20{suffix}']) / df[f'sma_20{suffix}'].replace(0, 1) * 100
            
            # EMAäº¤å‰ä¿¡å· - ğŸ”§ ä½¿ç”¨ä¼˜åŒ–çš„EMA
            df[f'ema_cross{suffix}'] = (df[f'ema_fast{suffix}'] > df[f'ema_slow{suffix}']).astype(int)
            
            # ä»·æ ¼åŠ¨é‡ (å¤šå‘¨æœŸ) - ğŸ”§ ä½¿ç”¨æ›´çŸ­å‘¨æœŸ
            df[f'momentum_3{suffix}'] = (df['close'] / df['close'].shift(3) - 1) * 100  # ğŸ”§ æ–°å¢3å‘¨æœŸåŠ¨é‡
            df[f'momentum_5{suffix}'] = (df['close'] / df['close'].shift(5) - 1) * 100
            df[f'momentum_10{suffix}'] = (df['close'] / df['close'].shift(10) - 1) * 100
            
            # æ³¢åŠ¨ç‡å˜åŒ–ç‡ - ğŸ”§ ä½¿ç”¨æ›´çŸ­çª—å£
            rolling_std_short = df['close'].rolling(3).std()  # ğŸ”§ ä»5æ”¹ä¸º3
            rolling_std_long = df['close'].rolling(10).std()   # ğŸ”§ ä»20æ”¹ä¸º10
            df[f'volatility_ratio{suffix}'] = rolling_std_short / rolling_std_long.replace(0, 1)
            
            # æˆäº¤é‡åŠ æƒä»·æ ¼ - ğŸ”§ ä½¿ç”¨æ›´çŸ­çª—å£
            df[f'vwap{suffix}'] = (df['close'] * df['volume']).rolling(10).sum() / df['volume'].rolling(10).sum()  # ğŸ”§ ä»20æ”¹ä¸º10
            df[f'price_vs_vwap{suffix}'] = (df['close'] - df[f'vwap{suffix}']) / df[f'vwap{suffix}'].replace(0, 1) * 100
            
            # é«˜ä½ç‚¹è·ç¦»
            df[f'high_low_pct{suffix}'] = (df['high'] - df['low']) / df['close'] * 100
            
            # ğŸ”µ 6. å™ªå£°æŒ‡æ ‡ (å¢åŠ å¤šæ ·æ€§) - ğŸ”§ ä¼˜åŒ–è®¡ç®—
            # RSIå¹³æ»‘
            df[f'rsi_smooth{suffix}'] = df[f'rsi_7{suffix}'].rolling(2).mean()  # ğŸ”§ ä½¿ç”¨RSI7å’Œæ›´çŸ­å¹³æ»‘çª—å£
            df[f'volume_momentum{suffix}'] = (df['volume'] / df['volume'].shift(1) - 1) * 100
            
            # ä»·æ ¼æŒ¯è¡å¼ºåº¦ - ğŸ”§ ä½¿ç”¨æ›´çŸ­çª—å£
            df[f'price_oscillation{suffix}'] = df['close'].rolling(5).apply(  # ğŸ”§ ä»10æ”¹ä¸º5
                lambda x: (x.max() - x.min()) / x.mean() * 100 if x.mean() != 0 else 0
            )
            
            # ğŸ”§ æ–°å¢ï¼šå¿«é€Ÿè¶‹åŠ¿æŒ‡æ ‡ï¼ˆå‡å°‘NaNï¼‰
            df[f'trend_fast{suffix}'] = (df['close'] > df[f'sma_5{suffix}']).astype(int)
            df[f'trend_strength{suffix}'] = (df[f'sma_5{suffix}'] - df[f'sma_10{suffix}']) / df[f'sma_10{suffix}'] * 100
            
            return df
            
        except Exception as e:
            logging.warning(f"âš ï¸ è®¡ç®—{interval}æŠ€æœ¯æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            return df
    
    def create_sequences(self, data, targets):
        X, y = [], []
        seq_length = 10  # ä½¿ç”¨10ä¸ªæ—¶é—´ç‚¹çš„æ•°æ®é¢„æµ‹
        
        for i in range(len(data) - seq_length):
            X.append(data[i:i+seq_length])
            if targets is not None:
                y.append(targets[i+seq_length])
        
        X_tensor = torch.FloatTensor(np.array(X))
        
        if targets is not None:
            y_tensor = torch.FloatTensor(np.array(y).reshape(-1, 1))
            return X_tensor, y_tensor
        else:
            # é¢„æµ‹æ¨¡å¼ï¼Œåªè¿”å›X
            return X_tensor

# æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹ç±»
class BitcoinPredictor:
    def __init__(self, config):
        self.config = config
        self.model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.api = EnhancedBinanceAPI(config['api_key'], config['api_secret'], config)
        self.data_processor = EnhancedDataProcessor(config)
        self.simulation_records = []
        # æ·»åŠ é©¬ä¸æ ¼å°”ç­–ç•¥å˜é‡
        self.current_bet_level = 0  # å½“å‰æŠ•æ³¨çº§åˆ«ï¼š0=5U, 1=10U, 2=30U, 3=90U, 4=250U
        self.martingale_bet_amounts = [5, 10, 30, 90, 250]  # é©¬ä¸æ ¼å°”æŠ•æ³¨é‡‘é¢åºåˆ—
        self.load_model()
    
    def load_model(self):
        if os.path.exists('model.pth'):
            try:
                # æ·»åŠ MinMaxScaleråˆ°å®‰å…¨åŠ è½½åˆ—è¡¨
                from torch.serialization import safe_globals
                with safe_globals([MinMaxScaler]):
                    model_state = torch.load('model.pth', weights_only=False, map_location=self.device)
                
                # ä»æ¨¡å‹å‚æ•°å®é™…å½¢çŠ¶ä¸­æ¨æ–­çœŸå®çš„hidden_size
                model_state_dict = model_state['model_state_dict']
                
                # æ£€æŸ¥attention.in_proj_weightçš„å½¢çŠ¶ï¼Œè¿™æ˜¯æœ€å¯é çš„åˆ¤æ–­æ–¹å¼
                if 'attention.in_proj_weight' in model_state_dict:
                    attention_shape = model_state_dict['attention.in_proj_weight'].shape
                    # attention shapeé€šå¸¸æ˜¯ [hidden_size*3, hidden_size*2]
                    real_hidden_size = attention_shape[1] // 2
                    logging.info(f"ğŸ“ ä»attentionæƒé‡å½¢çŠ¶{attention_shape}æ¨æ–­hidden_size={real_hidden_size}")
                # æ£€æŸ¥lstm.weight_hh_l0å½¢çŠ¶
                elif 'lstm.weight_hh_l0' in model_state_dict:
                    lstm_shape = model_state_dict['lstm.weight_hh_l0'].shape
                    # lstm.weight_hh_l0å½¢çŠ¶é€šå¸¸æ˜¯ [hidden_size*4, hidden_size]
                    real_hidden_size = lstm_shape[1]
                    logging.info(f"ğŸ“ ä»LSTMæƒé‡å½¢çŠ¶{lstm_shape}æ¨æ–­hidden_size={real_hidden_size}")
                # å¦‚æœæ— æ³•ä»æƒé‡æ¨æ–­ï¼Œä½¿ç”¨çŠ¶æ€å­—å…¸ä¸­è®°å½•çš„å€¼
                else:
                    real_hidden_size = model_state['hidden_size']
                    logging.warning(f"âš ï¸ æ— æ³•ä»æƒé‡å½¢çŠ¶æ¨æ–­ï¼Œä½¿ç”¨æ¨¡å‹è®°å½•çš„hidden_size={real_hidden_size}")
                
                # ä½¿ç”¨æ­£ç¡®æ¨æ–­çš„hidden_size
                input_size = model_state['input_size']
                num_layers = model_state['num_layers']
                dropout = model_state['dropout']
                
                logging.info(f"ğŸ“ ä½¿ç”¨æ¨æ–­çš„å‚æ•°: hidden_size={real_hidden_size}")
                
                # åˆ›å»ºä¸æƒé‡å½¢çŠ¶å®Œå…¨åŒ¹é…çš„æ¨¡å‹
                self.model = LSTMModel(input_size, real_hidden_size, num_layers, 1, dropout)
                self.model.load_state_dict(model_state['model_state_dict'])
                self.model.to(self.device)
                self.model.eval()
                
                # åŠ è½½æ•°æ®å¤„ç†å™¨çŠ¶æ€ - å…¼å®¹æ–°æ—§ç‰ˆæœ¬
                self.data_processor.features = model_state['features']
                if 'feature_scalers' in model_state:
                    self.data_processor.feature_scalers = model_state['feature_scalers']
                elif 'feature_scaler' in model_state:
                    # å…¼å®¹æ—§ç‰ˆæœ¬ï¼šå°†å•ä¸ªscalerè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                    self.data_processor.feature_scalers = {'1m': model_state['feature_scaler']}
                else:
                    logging.warning("âš ï¸ æ¨¡å‹æ–‡ä»¶ç¼ºå°‘scalerä¿¡æ¯ï¼Œéœ€è¦é‡æ–°è®­ç»ƒ")
                    return False
                
                # ğŸ§  åŠ è½½é›†æˆæ¨¡å‹
                if 'ensemble_models' in model_state:
                    self.ensemble_models = []
                    for ensemble_state in model_state['ensemble_models']:
                        # ä»é›†æˆæ¨¡å‹çŠ¶æ€å­—å…¸ä¸­è·å–æƒé‡å½¢çŠ¶
                        ensemble_dict = ensemble_state['model_state_dict']
                        
                        # åŒæ ·ï¼Œä»æƒé‡å½¢çŠ¶æ¨æ–­çœŸå®hidden_size
                        if 'attention.in_proj_weight' in ensemble_dict:
                            attn_shape = ensemble_dict['attention.in_proj_weight'].shape
                            ensemble_hidden_size = attn_shape[1] // 2
                            logging.info(f"ğŸ“ é›†æˆæ¨¡å‹ä»attentionæƒé‡å½¢çŠ¶{attn_shape}æ¨æ–­hidden_size={ensemble_hidden_size}")
                        elif 'lstm.weight_hh_l0' in ensemble_dict:
                            lstm_shape = ensemble_dict['lstm.weight_hh_l0'].shape
                            ensemble_hidden_size = lstm_shape[1]
                            logging.info(f"ğŸ“ é›†æˆæ¨¡å‹ä»LSTMæƒé‡å½¢çŠ¶{lstm_shape}æ¨æ–­hidden_size={ensemble_hidden_size}")
                        else:
                            # å¦‚æœæ— æ³•æ¨æ–­ï¼Œä½¿ç”¨æ¨¡å‹è®°å½•çš„å€¼
                            ensemble_hidden_size = ensemble_state.get('hidden_size', real_hidden_size)
                            logging.warning(f"âš ï¸ æ— æ³•æ¨æ–­é›†æˆæ¨¡å‹hidden_sizeï¼Œä½¿ç”¨è®°å½•å€¼={ensemble_hidden_size}")
                        
                        # é‡å»ºé›†æˆæ¨¡å‹
                        ensemble_model = EnhancedLSTMModel(
                            input_size, 
                            ensemble_hidden_size, 
                            num_layers, 
                            1, 
                            dropout
                        )
                        ensemble_model.load_state_dict(ensemble_dict)
                        ensemble_model.to(self.device)
                        ensemble_model.eval()
                        
                        self.ensemble_models.append({
                            'model': ensemble_model,
                            'accuracy': ensemble_state['accuracy'],
                            'weight': ensemble_state['weight']
                        })
                    
                    logging.info(f"âœ… æˆåŠŸåŠ è½½ {len(self.ensemble_models)} ä¸ªé›†æˆæ¨¡å‹")
                else:
                    logging.info("ğŸ“ æ—§ç‰ˆæœ¬æ¨¡å‹ï¼Œæ— é›†æˆæ¨¡å‹ä¿¡æ¯")
                
                logging.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (hidden_size={real_hidden_size})")
                return True
            except Exception as e:
                logging.error(f"âŒ åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å‚æ•°ä¸åŒ¹é…é”™è¯¯
                if "size mismatch" in str(e):
                    logging.error("ğŸ’¥ æ¨¡å‹å‚æ•°ä¸åŒ¹é…ï¼Œè¿™é€šå¸¸æ˜¯å› ä¸º:")
                    logging.error("   1. æ¨¡å‹æ¶æ„å·²æ›´æ–°")
                    logging.error("   2. é…ç½®å‚æ•°å‘ç”Ÿå˜åŒ–")
                    logging.error("   3. ç‰¹å¾æ•°é‡å‘ç”Ÿå˜åŒ–")
                    logging.error("")
                    logging.error("ğŸ”§ è§£å†³æ–¹æ³•:")
                    logging.error("   æ–¹æ³•1: åˆ é™¤æ—§æ¨¡å‹é‡æ–°è®­ç»ƒ")
                    logging.error("         del model.pth")
                    logging.error("         python bitcoin_prediction.py --train")
                    logging.error("")
                    logging.error("   æ–¹æ³•2: ä½¿ç”¨PowerShellåˆ é™¤")
                    logging.error("         Remove-Item model.pth")
                    logging.error("         python bitcoin_prediction.py --train")
                    logging.error("")
                    return False
                
                # å¦‚æœåŠ è½½å¤±è´¥ï¼Œå°è¯•æ—§ç‰ˆæœ¬å…¼å®¹æ–¹å¼åŠ è½½
                try:
                    logging.info("ğŸ”„ å°è¯•å…¼å®¹æ¨¡å¼åŠ è½½æ¨¡å‹...")
                    model_state = torch.load('model.pth', weights_only=False, map_location=self.device, pickle_module=pickle)
                    
                    # ä»æ¨¡å‹å‚æ•°å®é™…å½¢çŠ¶ä¸­æ¨æ–­çœŸå®çš„hidden_size
                    model_state_dict = model_state['model_state_dict']
                    
                    # æ£€æŸ¥attention.in_proj_weightçš„å½¢çŠ¶ï¼Œè¿™æ˜¯æœ€å¯é çš„åˆ¤æ–­æ–¹å¼
                    if 'attention.in_proj_weight' in model_state_dict:
                        attention_shape = model_state_dict['attention.in_proj_weight'].shape
                        # attention shapeé€šå¸¸æ˜¯ [hidden_size*3, hidden_size*2]
                        real_hidden_size = attention_shape[1] // 2
                        logging.info(f"ğŸ“ å…¼å®¹æ¨¡å¼: ä»attentionæƒé‡å½¢çŠ¶{attention_shape}æ¨æ–­hidden_size={real_hidden_size}")
                    # æ£€æŸ¥lstm.weight_hh_l0å½¢çŠ¶
                    elif 'lstm.weight_hh_l0' in model_state_dict:
                        lstm_shape = model_state_dict['lstm.weight_hh_l0'].shape
                        # lstm.weight_hh_l0å½¢çŠ¶é€šå¸¸æ˜¯ [hidden_size*4, hidden_size]
                        real_hidden_size = lstm_shape[1]
                        logging.info(f"ğŸ“ å…¼å®¹æ¨¡å¼: ä»LSTMæƒé‡å½¢çŠ¶{lstm_shape}æ¨æ–­hidden_size={real_hidden_size}")
                    # å¦‚æœæ— æ³•ä»æƒé‡æ¨æ–­ï¼Œä½¿ç”¨çŠ¶æ€å­—å…¸ä¸­è®°å½•çš„å€¼
                    else:
                        real_hidden_size = model_state['hidden_size']
                        logging.warning(f"âš ï¸ å…¼å®¹æ¨¡å¼: æ— æ³•ä»æƒé‡å½¢çŠ¶æ¨æ–­ï¼Œä½¿ç”¨æ¨¡å‹è®°å½•çš„hidden_size={real_hidden_size}")
                    
                    # ä½¿ç”¨æ­£ç¡®æ¨æ–­çš„hidden_size
                    input_size = model_state['input_size']
                    num_layers = model_state['num_layers']
                    dropout = model_state['dropout']
                    
                    logging.info(f"ğŸ“ å…¼å®¹æ¨¡å¼: ä½¿ç”¨æ¨æ–­çš„å‚æ•° hidden_size={real_hidden_size}")
                    
                    self.model = LSTMModel(input_size, real_hidden_size, num_layers, 1, dropout)
                    self.model.load_state_dict(model_state['model_state_dict'])
                    self.model.to(self.device)
                    self.model.eval()
                    
                    # åŠ è½½æ•°æ®å¤„ç†å™¨çŠ¶æ€ - å…¼å®¹æ–°æ—§ç‰ˆæœ¬
                    self.data_processor.features = model_state['features']
                    if 'feature_scalers' in model_state:
                        self.data_processor.feature_scalers = model_state['feature_scalers']
                    elif 'feature_scaler' in model_state:
                        # å…¼å®¹æ—§ç‰ˆæœ¬ï¼šå°†å•ä¸ªscalerè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                        self.data_processor.feature_scalers = {'1m': model_state['feature_scaler']}
                    else:
                        logging.warning("âš ï¸ æ¨¡å‹æ–‡ä»¶ç¼ºå°‘scalerä¿¡æ¯ï¼Œéœ€è¦é‡æ–°è®­ç»ƒ")
                        return False
                    
                    logging.info("âœ… æ¨¡å‹å…¼å®¹æ¨¡å¼åŠ è½½æˆåŠŸ")
                    return True
                except Exception as e2:
                    logging.error(f"âŒ å…¼å®¹æ¨¡å¼åŠ è½½æ¨¡å‹å¤±è´¥: {e2}")
                    if "size mismatch" in str(e2):
                        logging.error("ğŸ’¥ å³ä½¿å…¼å®¹æ¨¡å¼ä¹Ÿæ— æ³•è§£å†³å‚æ•°ä¸åŒ¹é…é—®é¢˜")
                        logging.error("ğŸ”§ è¯·åˆ é™¤æ¨¡å‹æ–‡ä»¶å¹¶é‡æ–°è®­ç»ƒ:")
                        logging.error("   del model.pth && python bitcoin_prediction.py --train")
                    return False
        else:
            logging.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œéœ€è¦å…ˆè®­ç»ƒæ¨¡å‹")
            return False
    
    def save_model(self, input_size):
        # å‡†å¤‡ä¿å­˜é›†æˆæ¨¡å‹çš„çŠ¶æ€å­—å…¸
        ensemble_states = []
        if hasattr(self, 'ensemble_models') and self.ensemble_models:
            for model_info in self.ensemble_models:
                ensemble_states.append({
                    'model_state_dict': model_info['model'].state_dict(),
                    'accuracy': model_info['accuracy'],
                    'weight': model_info['weight'],
                    'hidden_size': model_info['model'].hidden_size  # ä¿å­˜æ¯ä¸ªæ¨¡å‹çš„hidden_size
                })
        
        model_state = {
            'model_state_dict': self.model.state_dict(),
            'input_size': input_size,
            'hidden_size': self.config['hidden_size'],
            'num_layers': self.config['num_layers'],
            'dropout': self.config['dropout'],
            'features': self.data_processor.features,
            'feature_scalers': self.data_processor.feature_scalers,
            'ensemble_models': ensemble_states  # ä¿å­˜é›†æˆæ¨¡å‹
        }
        # ä½¿ç”¨pickleæ¨¡å—ä¿å­˜ï¼Œç¡®ä¿å…¼å®¹æ€§
        torch.save(model_state, 'model.pth', pickle_module=pickle)
        logging.info("æ¨¡å‹ä¿å­˜æˆåŠŸ")
    
    def train(self):
        logging.info("å¼€å§‹è®­ç»ƒå¢å¼ºæ¨¡å‹...")
        X, y = self.data_processor.fetch_and_prepare_enhanced_data(self.api, retrain=True)
        
        if X is None or y is None:
            logging.error("æ•°æ®å‡†å¤‡å¤±è´¥ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
            return False
        
        # ğŸ“Š æ•°æ®å¹³è¡¡å¤„ç†
        try:
            # å°†3Dæ•°æ®é‡å¡‘ä¸º2Dè¿›è¡ŒSMOTEå¤„ç†
            X_reshaped = X.reshape(X.shape[0], -1)
            y_flat = y.flatten()
            
            # æ£€æŸ¥ç±»åˆ«åˆ†å¸ƒ
            unique, counts = np.unique(y_flat, return_counts=True)
            logging.info(f"è®­ç»ƒæ•°æ®ç±»åˆ«åˆ†å¸ƒ: {dict(zip(unique, counts))}")
            
            # åªæœ‰åœ¨ç±»åˆ«ä¸å¹³è¡¡æ—¶æ‰ä½¿ç”¨SMOTE
            if len(unique) > 1 and min(counts) / max(counts) < 0.7:
                smote = SMOTE(random_state=42, k_neighbors=min(5, min(counts)-1))
                X_balanced, y_balanced = smote.fit_resample(X_reshaped, y_flat)
                
                # é‡å¡‘å›3Dæ ¼å¼
                X = X_balanced.reshape(-1, X.shape[1], X.shape[2])
                y = y_balanced.reshape(-1, 1)
                logging.info(f"âœ… SMOTEå¹³è¡¡åæ•°æ®é‡: {X.shape[0]}")
                
                # å†æ¬¡æ£€æŸ¥å¹³è¡¡åçš„ç±»åˆ«åˆ†å¸ƒ
                unique_balanced, counts_balanced = np.unique(y_balanced, return_counts=True)
                logging.info(f"å¹³è¡¡åç±»åˆ«åˆ†å¸ƒ: {dict(zip(unique_balanced, counts_balanced))}")
            else:
                logging.info("ğŸ“Š æ•°æ®å·²ç»ç›¸å¯¹å¹³è¡¡ï¼Œæ— éœ€SMOTEå¤„ç†")
                
        except Exception as e:
            logging.warning(f"âš ï¸ SMOTEå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®: {e}")
        
        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, train_size=self.config.get('train_size', 0.8), shuffle=False
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_dataset = TimeSeriesDataset(X_train, y_train)
        test_dataset = TimeSeriesDataset(X_test, y_test)
        
        train_loader = DataLoader(train_dataset, batch_size=self.config['batch_size'], shuffle=True)
        test_loader = DataLoader(test_dataset, batch_size=self.config['batch_size'], shuffle=False)
        
        # ğŸ§  æ¨¡å‹é›†æˆ - è®­ç»ƒå¤šä¸ªæ¨¡å‹
        self.ensemble_models = []
        best_accuracy = 0
        
        # è·å–è®­ç»ƒå‚æ•°
        input_size = X.shape[2]
        base_hidden_size = self.config['hidden_size']  # ä½¿ç”¨é…ç½®ä¸­çš„hidden_sizeä½œä¸ºåŸºç¡€
        logging.info(f"ğŸ“ è®­ç»ƒæ–°æ¨¡å‹ï¼Œä½¿ç”¨é…ç½®ä¸­çš„hidden_size={base_hidden_size}")
        
        # ğŸ†• æ·»åŠ è®­ç»ƒæ›²çº¿å¯è§†åŒ–æ•°æ®æ”¶é›†
        all_train_losses = []
        all_val_accuracies = []
        
        for model_idx in range(3):  # è®­ç»ƒ3ä¸ªä¸åŒçš„æ¨¡å‹
            logging.info(f"ğŸ”„ è®­ç»ƒç¬¬ {model_idx + 1}/3 ä¸ªé›†æˆæ¨¡å‹...")
            
            # åˆå§‹åŒ–æ¨¡å‹ - æ¯ä¸ªæ¨¡å‹ä½¿ç”¨ç¨å¾®ä¸åŒçš„å‚æ•°
            hidden_size = base_hidden_size + (model_idx * 16)  # ä¸åŒæ¨¡å‹ä¸åŒéšè—å±‚å¤§å°
            
            model = EnhancedLSTMModel(
                input_size, 
                hidden_size, 
                self.config['num_layers'], 
                1, 
                self.config['dropout']
            )
            model.to(self.device)
            
            # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
            criterion = nn.BCELoss()
            optimizer = optim.Adam(model.parameters(), lr=self.config['learning_rate'] * (1 + model_idx * 0.1))
            
            # ğŸ†• æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦å™¨
            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
                optimizer, mode='min', factor=0.5, patience=5
            )
            
            # ğŸ“… è®­ç»ƒå¾ªç¯
            best_model_accuracy = 0
            model_train_losses = []
            model_val_accuracies = []
            
            for epoch in range(self.config['epochs']):
                model.train()
                train_loss = 0
                for batch_X, batch_y in train_loader:
                    batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)
                    
                    # å‰å‘ä¼ æ’­
                    outputs = model(batch_X)
                    loss = criterion(outputs, batch_y)
                    
                    # åå‘ä¼ æ’­å’Œä¼˜åŒ–
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()
                    
                    train_loss += loss.item()
                
                # è®¡ç®—éªŒè¯é›†å‡†ç¡®ç‡
                model.eval()
                correct = 0
                total = 0
                val_loss = 0
                with torch.no_grad():
                    for batch_X, batch_y in test_loader:
                        batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)
                        outputs = model(batch_X)
                        val_loss += criterion(outputs, batch_y).item()
                        predicted = (outputs > 0.5).float()
                        total += batch_y.size(0)
                        correct += (predicted == batch_y).sum().item()
                
                accuracy = correct / total if total > 0 else 0
                
                # è®°å½•è®­ç»ƒæŒ‡æ ‡
                avg_train_loss = train_loss/len(train_loader)
                avg_val_loss = val_loss/len(test_loader)
                model_train_losses.append(avg_train_loss)
                model_val_accuracies.append(accuracy)
                
                # æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨
                old_lr = optimizer.param_groups[0]['lr']
                scheduler.step(avg_val_loss)
                new_lr = optimizer.param_groups[0]['lr']
                
                # æ‰‹åŠ¨è®°å½•å­¦ä¹ ç‡å˜åŒ–
                if new_lr != old_lr:
                    logging.info(f"å­¦ä¹ ç‡ä» {old_lr:.6f} è°ƒæ•´ä¸º {new_lr:.6f}")
                
                if accuracy > best_model_accuracy:
                    best_model_accuracy = accuracy
                    # ä¿å­˜æœ€ä½³æ¨¡å‹çŠ¶æ€
                    best_model_state = {
                        'epoch': epoch,
                        'model_state_dict': model.state_dict(),
                        'optimizer_state_dict': optimizer.state_dict(),
                        'accuracy': accuracy,
                    }
                
                if (epoch + 1) % 10 == 0 or epoch == 0:
                    logging.info(f"æ¨¡å‹{model_idx+1} Epoch [{epoch+1}/{self.config['epochs']}], "
                               f"Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, "
                               f"Accuracy: {accuracy:.4f}")
            
            # æ”¶é›†è¯¥æ¨¡å‹çš„è®­ç»ƒæ›²çº¿æ•°æ®
            all_train_losses.append(model_train_losses)
            all_val_accuracies.append(model_val_accuracies)
            
            # ğŸ¯ æ¯ä¸ªæ¨¡å‹è®­ç»ƒå®Œæˆåæ·»åŠ åˆ°é›†æˆ
            # åŠ è½½æœ€ä½³æ¨¡å‹çŠ¶æ€
            if 'best_model_state' in locals():
                model.load_state_dict(best_model_state['model_state_dict'])
                logging.info(f"åŠ è½½æœ€ä½³æ¨¡å‹çŠ¶æ€ (Epoch {best_model_state['epoch']+1}, Accuracy: {best_model_state['accuracy']:.4f})")
            
            self.ensemble_models.append({
                'model': model,
                'accuracy': best_model_accuracy,
                'weight': best_model_accuracy  # ä½¿ç”¨å‡†ç¡®ç‡ä½œä¸ºæƒé‡
            })
            
            # æ›´æ–°æœ€ä½³å•æ¨¡å‹
            if best_model_accuracy > best_accuracy:
                best_accuracy = best_model_accuracy
                self.model = model
        
        # ğŸ”§ é›†æˆæƒé‡å½’ä¸€åŒ–
        total_weight = sum([m['weight'] for m in self.ensemble_models])
        for model_info in self.ensemble_models:
            model_info['weight'] /= total_weight
            
        logging.info(f"âœ… æ¨¡å‹é›†æˆè®­ç»ƒå®Œæˆ!")
        logging.info(f"ğŸ“Š é›†æˆæ¨¡å‹æƒé‡: {[f'{m['weight']:.3f}' for m in self.ensemble_models]}")
        logging.info(f"ğŸ¯ æœ€ä½³å•æ¨¡å‹å‡†ç¡®ç‡: {best_accuracy:.4f}")
        
        # ğŸ†• ç”Ÿæˆè®­ç»ƒæ›²çº¿å¯è§†åŒ–
        try:
            self.plot_training_curves(all_train_losses, all_val_accuracies)
        except Exception as e:
            logging.error(f"ç”Ÿæˆè®­ç»ƒæ›²çº¿å¯è§†åŒ–å¤±è´¥: {e}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        self.save_model(input_size)
        return True
    
    def plot_training_curves(self, all_train_losses, all_val_accuracies):
        """ç”Ÿæˆè®­ç»ƒæ›²çº¿å¯è§†åŒ–å›¾è¡¨"""
        try:
            plt.style.use('dark_background')
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
            
            # ç»˜åˆ¶è®­ç»ƒæŸå¤±æ›²çº¿
            ax1.set_title('è®­ç»ƒæŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')
            ax1.set_xlabel('Epoch')
            ax1.set_ylabel('Loss')
            
            colors = ['#00BFFF', '#00FF7F', '#FFD700']  # è“è‰², ç»¿è‰², é»„è‰²
            
            for i, losses in enumerate(all_train_losses):
                ax1.plot(losses, label=f'æ¨¡å‹ {i+1}', color=colors[i], linewidth=2)
            
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # ç»˜åˆ¶éªŒè¯å‡†ç¡®ç‡æ›²çº¿
            ax2.set_title('éªŒè¯å‡†ç¡®ç‡æ›²çº¿', fontsize=14, fontweight='bold')
            ax2.set_xlabel('Epoch')
            ax2.set_ylabel('Accuracy')
            ax2.set_ylim(0, 1)
            
            for i, accuracies in enumerate(all_val_accuracies):
                ax2.plot(accuracies, label=f'æ¨¡å‹ {i+1}', color=colors[i], linewidth=2)
            
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig('training_curves.png', dpi=300)
            logging.info("âœ… è®­ç»ƒæ›²çº¿å¯è§†åŒ–å·²ä¿å­˜è‡³ training_curves.png")
        except Exception as e:
            logging.error(f"ç»˜åˆ¶è®­ç»ƒæ›²çº¿å¤±è´¥: {e}")
    
    def predict(self):
        """ä½¿ç”¨å¢å¼ºé¢„æµ‹ç³»ç»Ÿè¿›è¡Œé¢„æµ‹ - ä¿æŒå®Œæ•´å‡†ç¡®ç‡"""
        try:
            # è·å–å®æ—¶æ•°æ®
            data = self.data_processor.fetch_and_prepare_enhanced_data(self.api, retrain=False)
            if data is None:
                return None
            
            X, df = data
            if X is None or len(X) == 0:
                return None
            
            # ä½¿ç”¨æœ€æ–°çš„æ•°æ®ç‚¹è¿›è¡Œé¢„æµ‹
            last_sequence = torch.FloatTensor(X[-1:]).to(self.device)
            
            predictions = []
            model_confidences = []
            
            # ğŸ§  é›†æˆé¢„æµ‹
            if hasattr(self, 'ensemble_models') and self.ensemble_models:
                with torch.no_grad():
                    for i, model_info in enumerate(self.ensemble_models):
                        try:
                            model = model_info['model']
                            weight = model_info['weight']
                            
                            model.eval()
                            pred = model(last_sequence)
                            confidence = float(pred.cpu().numpy()[0][0])
                            
                            predictions.append(confidence)
                            model_confidences.append(confidence)
                        except Exception as e:
                            continue
                
                if not predictions:
                    return None
                
                # æ£€æŸ¥é¢„æµ‹ç»“æœä¸­çš„NaNå€¼
                valid_predictions = [p for p in predictions if not np.isnan(p)]
                if len(valid_predictions) == 0:
                    return None
                elif len(valid_predictions) < len(predictions):
                    predictions = valid_predictions
                    # é‡æ–°è®¡ç®—æƒé‡
                    valid_models = self.ensemble_models[:len(valid_predictions)]
                    total_weight = sum(model['weight'] for model in valid_models)
                    for model in valid_models:
                        model['weight'] = model['weight'] / total_weight
                
                # åŠ æƒå¹³å‡é¢„æµ‹
                weighted_prediction = sum([
                    pred * model_info['weight'] 
                    for pred, model_info in zip(predictions, self.ensemble_models[:len(predictions)])
                ])
                
                # æ£€æŸ¥åŠ æƒé¢„æµ‹ç»“æœ
                if np.isnan(weighted_prediction):
                    return None
                
                # è®¡ç®—é¢„æµ‹æ–¹å·®
                prediction_variance = np.var(predictions)
                
            else:
                # å•æ¨¡å‹é¢„æµ‹
                if self.model is None:
                    return None
                
                self.model.eval()
                with torch.no_grad():
                    prediction = self.model(last_sequence)
                    weighted_prediction = float(prediction.cpu().numpy()[0][0])
                    model_confidences = [weighted_prediction]
                    prediction_variance = 0
            
            # ğŸ¯ å®Œæ•´æ™ºèƒ½ç½®ä¿¡åº¦è®¡ç®— - ä¿æŒæ‰€æœ‰å‡†ç¡®ç‡ä¼˜åŒ–
            # 1. åŸºç¡€ç½®ä¿¡åº¦ (è·ç¦»0.5çš„ç¨‹åº¦)
            base_confidence = abs(weighted_prediction - 0.5) * 2
            
            # 2. ğŸ”§ ä¼˜åŒ–çš„é˜²è¿‡æ‹Ÿåˆæœºåˆ¶
            confidence_adjustments = []
            
            # ğŸ”§ æ”¹è¿›çš„æ¨¡å‹åˆ†æ­§æƒ©ç½šï¼šä½¿ç”¨è½¯æƒ©ç½šæœºåˆ¶
            if prediction_variance > 0.01:  # å¦‚æœæ¨¡å‹åˆ†æ­§è¾ƒå¤§
                # ä½¿ç”¨å¯¹æ•°å‡½æ•°è¿›è¡Œè½¯æƒ©ç½šï¼Œé¿å…è¿‡åº¦æƒ©ç½š
                variance_penalty = min(0.25, np.log(1 + prediction_variance * 20) * 0.1)  # ğŸ”§ æœ€å¤§æƒ©ç½š25%
                confidence_adjustments.append(f"åˆ†æ­§æƒ©ç½š: -{variance_penalty:.3f}")
                base_confidence *= (1 - variance_penalty)
            
            # ğŸ”§ æ”¹è¿›çš„ä¸€è‡´æ€§æƒ©ç½šï¼šä½¿ç”¨æ¸è¿›æƒ©ç½š
            if prediction_variance < 0.001 and len(predictions) > 1:
                # æ ¹æ®ä¸€è‡´æ€§ç¨‹åº¦è¿›è¡Œæ¸è¿›æƒ©ç½š
                consistency_level = 1 - prediction_variance * 1000  # 0-1ä¹‹é—´
                consistency_penalty = min(0.2, consistency_level * 0.2)  # ğŸ”§ æœ€å¤§æƒ©ç½š20%
                confidence_adjustments.append(f"è¿‡åº¦ä¸€è‡´æƒ©ç½š: -{consistency_penalty:.3f}")
                base_confidence *= (1 - consistency_penalty)
            
            # ğŸ”§ æ”¹è¿›çš„æå€¼æƒ©ç½šï¼šæ¸è¿›å¼æƒ©ç½š
            extreme_distance = max(0, max(0.1 - weighted_prediction, weighted_prediction - 0.9))
            if extreme_distance > 0:
                extreme_penalty = min(0.15, extreme_distance * 1.5)  # ğŸ”§ æœ€å¤§æƒ©ç½š15%
                confidence_adjustments.append(f"æå€¼æƒ©ç½š: -{extreme_penalty:.3f}")
                base_confidence *= (1 - extreme_penalty)
            
            # 3. æŠ€æœ¯æŒ‡æ ‡éªŒè¯åŠ æˆ
            try:
                tech_strength = self.calculate_enhanced_technical_strength()
                if tech_strength > 0:
                    confidence_adjustments.append(f"æŠ€æœ¯æŒ‡æ ‡åŠ æˆ: +{tech_strength:.3f}")
                    base_confidence += tech_strength
            except Exception as e:
                tech_strength = 0
            
            # 4. ğŸ”§ å¢å¼ºçš„å¸‚åœºæƒ…ç»ªéªŒè¯åŠ æˆ
            try:
                sentiment_strength = self.calculate_enhanced_sentiment_strength()  # ğŸ”§ ä½¿ç”¨å¢å¼ºç‰ˆæœ¬
                if sentiment_strength > 0:
                    confidence_adjustments.append(f"æƒ…ç»ªåˆ†æåŠ æˆ: +{sentiment_strength:.3f}")
                    base_confidence += sentiment_strength
            except Exception as e:
                sentiment_strength = 0
            
            # 5. ğŸ”§ æ–°å¢ï¼šææ…Œè´ªå©ªæŒ‡æ•°åŠ æˆ
            try:
                if hasattr(self.data_processor, 'sentiment_analyzer') and self.data_processor.sentiment_analyzer:
                    fear_greed_index = self.data_processor.sentiment_analyzer.get_fear_greed_index()
                    # å°†ææ…Œè´ªå©ªæŒ‡æ•°è½¬æ¢ä¸ºç½®ä¿¡åº¦è°ƒæ•´
                    if fear_greed_index < 20:  # æåº¦ææ…Œ
                        fg_adjustment = 0.05 if weighted_prediction < 0.5 else -0.02  # ææ…Œæ—¶çœ‹è·Œæ›´å¯ä¿¡
                    elif fear_greed_index > 80:  # æåº¦è´ªå©ª
                        fg_adjustment = 0.05 if weighted_prediction > 0.5 else -0.02  # è´ªå©ªæ—¶çœ‹æ¶¨æ›´å¯ä¿¡
                    else:
                        fg_adjustment = 0
                    
                    if fg_adjustment != 0:
                        confidence_adjustments.append(f"ææ…Œè´ªå©ªæŒ‡æ•°: {fg_adjustment:+.3f}")
                        base_confidence += fg_adjustment
            except Exception as e:
                pass
            
            # 6. ğŸ”§ è½¯ä¸‹é™æœºåˆ¶ï¼šç¡®ä¿ç½®ä¿¡åº¦ä¸ä¼šè¿‡ä½
            soft_floor = self.config.get('soft_confidence_floor', 15) / 100  # é»˜è®¤15%
            if base_confidence < soft_floor:
                floor_adjustment = soft_floor - base_confidence
                confidence_adjustments.append(f"è½¯ä¸‹é™ä¿æŠ¤: +{floor_adjustment:.3f}")
                base_confidence = soft_floor
            
            # 7. æœ€ç»ˆç½®ä¿¡åº¦é™åˆ¶ (è½¯ä¸‹é™%-95%)
            final_confidence = max(soft_floor, min(0.95, base_confidence))
            
            # 8. ğŸ”§ åŠ¨æ€äº¤æ˜“é—¨æ§›æ£€æŸ¥
            min_threshold = self.config.get('min_confidence_threshold', 60) / 100  # é»˜è®¤60%
            trade_recommended = final_confidence >= min_threshold
            
            # 9. é¢„æµ‹ç»“æœ
            direction = "ä¸Šæ¶¨" if weighted_prediction > 0.5 else "ä¸‹è·Œ"
            trade_signal = "ğŸ“ˆ ä¹°æ¶¨" if weighted_prediction > 0.5 else "ğŸ“‰ ä¹°è·Œ"
            
            # ğŸ”§ æ ¹æ®ç½®ä¿¡åº¦è°ƒæ•´äº¤æ˜“ä¿¡å·
            if not trade_recommended:
                trade_signal = "â¸ï¸ è§‚æœ›"
            
            # ğŸ†• æ–°å¢ï¼šä¸¥æ ¼çš„æŠ€æœ¯æŒ‡æ ‡è¿‡æ»¤æ¡ä»¶
            # è·å–å½“å‰æŠ€æœ¯æŒ‡æ ‡
            try:
                # è·å–æœ€æ–°çš„æŠ€æœ¯æŒ‡æ ‡
                current_price = self.api.get_latest_price(self.config['symbol'])
                if current_price is None:
                    logging.warning("âš ï¸ æ— æ³•è·å–å½“å‰ä»·æ ¼ï¼Œè·³è¿‡æŠ€æœ¯æŒ‡æ ‡è¿‡æ»¤")
                else:
                    # è·å–æŠ€æœ¯æŒ‡æ ‡æ•°æ®
                    klines_1m = self.api.client.get_klines(symbol=self.config['symbol'], interval='1m', limit=100)
                    if klines_1m:
                        df_tech = pd.DataFrame(klines_1m, columns=[
                            'open_time', 'open', 'high', 'low', 'close', 'volume',
                            'close_time', 'quote_asset_volume', 'number_of_trades',
                            'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'
                        ])
                        
                        # æ•°æ®ç±»å‹è½¬æ¢
                        numeric_columns = ['open', 'high', 'low', 'close', 'volume']
                        for col in numeric_columns:
                            df_tech[col] = pd.to_numeric(df_tech[col])
                        
                        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                        # RSI
                        rsi_14 = ta.momentum.rsi(df_tech['close'], window=14).iloc[-1]
                        
                        # MACD
                        macd = ta.trend.MACD(df_tech['close'])
                        macd_line = macd.macd().iloc[-1]
                        macd_signal = macd.macd_signal().iloc[-1]
                        macd_hist = macd.macd_diff().iloc[-1]
                        
                        # å¸ƒæ—å¸¦
                        bollinger = ta.volatility.BollingerBands(df_tech['close'])
                        bb_upper = bollinger.bollinger_hband().iloc[-1]
                        bb_middle = bollinger.bollinger_mavg().iloc[-1]
                        bb_lower = bollinger.bollinger_lband().iloc[-1]
                        
                        # ç§»åŠ¨å¹³å‡çº¿
                        sma_20 = ta.trend.sma_indicator(df_tech['close'], window=20).iloc[-1]
                        sma_50 = ta.trend.sma_indicator(df_tech['close'], window=50).iloc[-1]
                        
                        # æˆäº¤é‡
                        volume_sma = df_tech['volume'].rolling(20).mean().iloc[-1]
                        current_volume = df_tech['volume'].iloc[-1]
                        
                        # ğŸ†• ä¸¥æ ¼çš„æŠ€æœ¯æŒ‡æ ‡è¿‡æ»¤è§„åˆ™
                        tech_filters_passed = True
                        filter_messages = []
                        
                        # è§„åˆ™1: è¶…ä¹°/è¶…å–è¿‡æ»¤
                        if direction == "ä¸Šæ¶¨" and rsi_14 > 70:
                            tech_filters_passed = False
                            filter_messages.append(f"RSIè¿‡é«˜({rsi_14:.1f} > 70)ï¼Œä¸é€‚åˆåšå¤š")
                        elif direction == "ä¸‹è·Œ" and rsi_14 < 30:
                            tech_filters_passed = False
                            filter_messages.append(f"RSIè¿‡ä½({rsi_14:.1f} < 30)ï¼Œä¸é€‚åˆåšç©º")
                        
                        # è§„åˆ™2: MACDæ–¹å‘ä¸é¢„æµ‹æ–¹å‘ä¸€è‡´æ€§æ£€æŸ¥
                        if direction == "ä¸Šæ¶¨" and macd_hist < 0:
                            tech_filters_passed = False
                            filter_messages.append(f"MACDæŸ±çŠ¶å›¾ä¸ºè´Ÿ({macd_hist:.4f})ï¼Œä¸åšå¤šä¿¡å·ä¸ä¸€è‡´")
                        elif direction == "ä¸‹è·Œ" and macd_hist > 0:
                            tech_filters_passed = False
                            filter_messages.append(f"MACDæŸ±çŠ¶å›¾ä¸ºæ­£({macd_hist:.4f})ï¼Œä¸åšç©ºä¿¡å·ä¸ä¸€è‡´")
                        
                        # è§„åˆ™3: å¸ƒæ—å¸¦ä½ç½®æ£€æŸ¥
                        current_price = df_tech['close'].iloc[-1]
                        if direction == "ä¸Šæ¶¨" and current_price > bb_upper:
                            tech_filters_passed = False
                            filter_messages.append(f"ä»·æ ¼å·²è¶…è¿‡å¸ƒæ—å¸¦ä¸Šè½¨ï¼Œä¸é€‚åˆåšå¤š")
                        elif direction == "ä¸‹è·Œ" and current_price < bb_lower:
                            tech_filters_passed = False
                            filter_messages.append(f"ä»·æ ¼å·²ä½äºå¸ƒæ—å¸¦ä¸‹è½¨ï¼Œä¸é€‚åˆåšç©º")
                        
                        # è§„åˆ™4: è¶‹åŠ¿æ–¹å‘æ£€æŸ¥
                        if direction == "ä¸Šæ¶¨" and current_price < sma_20:
                            tech_filters_passed = False
                            filter_messages.append(f"ä»·æ ¼ä½äº20æ—¥å‡çº¿ï¼Œä¸åšå¤šä¿¡å·ä¸ä¸€è‡´")
                        elif direction == "ä¸‹è·Œ" and current_price > sma_20:
                            tech_filters_passed = False
                            filter_messages.append(f"ä»·æ ¼é«˜äº20æ—¥å‡çº¿ï¼Œä¸åšç©ºä¿¡å·ä¸ä¸€è‡´")
                        
                        # è§„åˆ™5: æˆäº¤é‡ç¡®è®¤
                        if current_volume < volume_sma * 0.7:
                            tech_filters_passed = False
                            filter_messages.append(f"æˆäº¤é‡è¿‡ä½ï¼Œä¿¡å·å¯é æ€§é™ä½")
                        
                        # å¦‚æœæ²¡æœ‰é€šè¿‡æŠ€æœ¯æŒ‡æ ‡è¿‡æ»¤ï¼Œåˆ™ä¸æ¨èäº¤æ˜“
                        if not tech_filters_passed:
                            trade_recommended = False
                            trade_signal = "â¸ï¸ è§‚æœ› (æŠ€æœ¯æŒ‡æ ‡è¿‡æ»¤)"
                            logging.info(f"âš ï¸ æŠ€æœ¯æŒ‡æ ‡è¿‡æ»¤: {'; '.join(filter_messages)}")
            except Exception as e:
                logging.warning(f"âš ï¸ æŠ€æœ¯æŒ‡æ ‡è¿‡æ»¤å‡ºé”™: {e}")
            
            result = {
                'timestamp': datetime.now(),
                'current_price': self.api.get_latest_price('BTCUSDT'),
                'prediction': weighted_prediction,
                'confidence': final_confidence * 100,  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
                'direction': direction,
                'trade_signal': trade_signal,
                'trade_recommended': trade_recommended,  # ğŸ”§ æ–°å¢
                'confidence_threshold': min_threshold * 100,  # ğŸ”§ æ–°å¢
                'model_predictions': model_confidences,
                'technical_strength': tech_strength,
                'sentiment_strength': sentiment_strength,
                'prediction_variance': prediction_variance,
                'confidence_adjustments': confidence_adjustments,
                'tech_filters_passed': locals().get('tech_filters_passed', True),
                'filter_messages': locals().get('filter_messages', [])
            }
            
            return result
            
        except Exception as e:
            return None
    
    def calculate_technical_strength(self):
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¼ºåº¦ï¼Œç”¨äºå¢å¼ºç½®ä¿¡åº¦"""
        try:
            # è·å–æœ€æ–°çš„æŠ€æœ¯æŒ‡æ ‡æ•°æ®
            api = self.api
            klines_1m = api.client.get_klines(symbol='BTCUSDT', interval='1m', limit=100)
            
            if not klines_1m:
                return 0
            
            df = pd.DataFrame(klines_1m, columns=[
                'open_time', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_asset_volume', 'number_of_trades',
                'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'
            ])
            
            # æ•°æ®ç±»å‹è½¬æ¢
            numeric_columns = ['open', 'high', 'low', 'close', 'volume']
            for col in numeric_columns:
                df[col] = pd.to_numeric(df[col])
            
            # è®¡ç®—å…³é”®æŠ€æœ¯æŒ‡æ ‡å¼ºåº¦
            strength_score = 0
            
            # RSIå¼ºåº¦ (è¶…ä¹°/è¶…å–ä¿¡å·)
            try:
                rsi = ta.momentum.rsi(df['close'], window=14).iloc[-1]
                if rsi < 30 or rsi > 70:  # è¶…ä¹°è¶…å–
                    strength_score += 0.1
            except:
                pass
            
            # MACDå¼ºåº¦
            try:
                macd = ta.trend.MACD(df['close'])
                macd_line = macd.macd().iloc[-1]
                macd_signal = macd.macd_signal().iloc[-1]
                if abs(macd_line - macd_signal) > 0.1:  # MACDèƒŒç¦»å¼ºçƒˆ
                    strength_score += 0.1
            except:
                pass
            
            # æˆäº¤é‡å¼ºåº¦
            try:
                volume_ma = df['volume'].rolling(20).mean().iloc[-1]
                current_volume = df['volume'].iloc[-1]
                if current_volume > volume_ma * 1.5:  # æˆäº¤é‡æ”¾å¤§
                    strength_score += 0.05
            except:
                pass
            
            # å¸ƒæ—å¸¦ä½ç½®
            try:
                bollinger = ta.volatility.BollingerBands(df['close'])
                bb_position = bollinger.bollinger_pband().iloc[-1]
                if bb_position > 0.8 or bb_position < 0.2:  # æ¥è¿‘å¸ƒæ—å¸¦è¾¹ç•Œ
                    strength_score += 0.05
            except:
                pass
            
            return min(0.3, strength_score)  # æœ€å¤šè´¡çŒ®30%ç½®ä¿¡åº¦
            
        except Exception as e:
            logging.warning(f"è®¡ç®—æŠ€æœ¯å¼ºåº¦å¤±è´¥: {e}")
            return 0
    
    def calculate_enhanced_technical_strength(self):
        """è®¡ç®—å¢å¼ºæŠ€æœ¯æŒ‡æ ‡å¼ºåº¦ï¼Œç”¨äºå¢å¼ºç½®ä¿¡åº¦"""
        try:
            # è·å–æœ€æ–°çš„æŠ€æœ¯æŒ‡æ ‡æ•°æ®
            api = self.api
            klines_1m = api.client.get_klines(symbol='BTCUSDT', interval='1m', limit=100)
            
            if not klines_1m:
                logging.warning("æ— æ³•è·å–Kçº¿æ•°æ®")
                return 0
            
            df = pd.DataFrame(klines_1m, columns=[
                'open_time', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_asset_volume', 'number_of_trades',
                'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'
            ])
            
            # æ•°æ®ç±»å‹è½¬æ¢
            numeric_columns = ['open', 'high', 'low', 'close', 'volume']
            for col in numeric_columns:
                df[col] = pd.to_numeric(df[col])
            
            if len(df) < 50:  # æ•°æ®ä¸è¶³
                logging.warning("Kçº¿æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æŠ€æœ¯æŒ‡æ ‡")
                return 0
            
            # ğŸ¯ ç®€åŒ–ä½†ç¨³å®šçš„æŠ€æœ¯æŒ‡æ ‡å¼ºåº¦è®¡ç®—
            strength_score = 0
            
            # 1. ç®€å•ç§»åŠ¨å¹³å‡çº¿è¶‹åŠ¿
            try:
                ma_5 = df['close'].rolling(5).mean().iloc[-1]
                ma_20 = df['close'].rolling(20).mean().iloc[-1]
                current_price = df['close'].iloc[-1]
                
                # å‡çº¿æ’åˆ—
                if ma_5 > ma_20 and current_price > ma_5:  # ä¸Šå‡è¶‹åŠ¿
                    strength_score += 0.08
                elif ma_5 < ma_20 and current_price < ma_5:  # ä¸‹é™è¶‹åŠ¿
                    strength_score += 0.08
            except Exception as e:
                logging.warning(f"è®¡ç®—ç§»åŠ¨å¹³å‡çº¿å¤±è´¥: {e}")
            
            # 2. ä»·æ ¼åŠ¨é‡ï¼ˆç®€åŒ–ç‰ˆRSIæ¦‚å¿µï¼‰
            try:
                price_changes = df['close'].diff().dropna()
                if len(price_changes) >= 14:
                    gains = price_changes.where(price_changes > 0, 0)
                    losses = -price_changes.where(price_changes < 0, 0)
                    
                    avg_gain = gains.rolling(14).mean().iloc[-1]
                    avg_loss = losses.rolling(14).mean().iloc[-1]
                    
                    if avg_loss > 0:
                        rs = avg_gain / avg_loss
                        rsi = 100 - (100 / (1 + rs))
                        
                        # RSIä¿¡å·
                        if rsi < 30 or rsi > 70:  # è¶…ä¹°è¶…å–
                            strength_score += 0.06
            except Exception as e:
                logging.warning(f"è®¡ç®—ä»·æ ¼åŠ¨é‡å¤±è´¥: {e}")
            
            # 3. æˆäº¤é‡ç¡®è®¤
            try:
                volume_ma = df['volume'].rolling(20).mean().iloc[-1]
                current_volume = df['volume'].iloc[-1]
                
                if current_volume > volume_ma * 1.5:  # æˆäº¤é‡æ”¾å¤§
                    strength_score += 0.05
            except Exception as e:
                logging.warning(f"è®¡ç®—æˆäº¤é‡ç¡®è®¤å¤±è´¥: {e}")
            
            # 4. ä»·æ ¼æ³¢åŠ¨ç‡
            try:
                price_volatility = df['close'].rolling(20).std().iloc[-1]
                volatility_ma = df['close'].rolling(20).std().rolling(10).mean().iloc[-1]
                
                if price_volatility > volatility_ma * 1.2:  # æ³¢åŠ¨å¢å¼º
                    strength_score += 0.04
            except Exception as e:
                logging.warning(f"è®¡ç®—æ³¢åŠ¨ç‡å¤±è´¥: {e}")
            
            final_score = min(0.2, strength_score)  # æœ€å¤šè´¡çŒ®20%ç½®ä¿¡åº¦
            logging.info(f"ğŸ“Š æŠ€æœ¯æŒ‡æ ‡å¼ºåº¦: {final_score:.4f}")
            return final_score
            
        except Exception as e:
            logging.error(f"è®¡ç®—å¢å¼ºæŠ€æœ¯æŒ‡æ ‡å¼ºåº¦å¤±è´¥: {e}")
            return 0
    
    def calculate_enhanced_sentiment_strength(self):
        """ğŸ”§ æ–°å¢ï¼šè®¡ç®—å¢å¼ºçš„æƒ…ç»ªå¼ºåº¦ï¼Œæ•´åˆå¤šç»´åº¦æƒ…ç»ªæŒ‡æ ‡"""
        try:
            if not hasattr(self.data_processor, 'sentiment_analyzer') or not self.data_processor.sentiment_analyzer:
                return 0
            
            sentiment_analyzer = self.data_processor.sentiment_analyzer
            
            # 1. è®¢å•ç°¿æƒ…ç»ªåˆ†æ
            book_sentiment = sentiment_analyzer.analyze_order_book_sentiment()
            
            # åŸºç¡€æƒ…ç»ªå¾—åˆ† (0-1)
            base_sentiment = book_sentiment.get('sentiment_score', 0.5)
            
            # ğŸ”§ ä¹°å¢™/å–å¢™åˆ†æ
            wall_ratio = book_sentiment.get('wall_ratio', 1.0)
            wall_strength = 0
            if wall_ratio > 1.5:  # ä¹°å¢™å¼ºäºå–å¢™
                wall_strength = min(0.05, (wall_ratio - 1) * 0.02)
            elif wall_ratio < 0.67:  # å–å¢™å¼ºäºä¹°å¢™
                wall_strength = max(-0.05, (wall_ratio - 1) * 0.02)
            
            # ğŸ”§ æ·±åº¦ä¸å¹³è¡¡åˆ†æ
            deep_imbalance = book_sentiment.get('deep_imbalance', 0)
            depth_strength = min(0.03, abs(deep_imbalance) * 0.1) if abs(deep_imbalance) > 0.1 else 0
            if deep_imbalance < 0:  # å–ç›˜æ·±åº¦æ›´å¤§
                depth_strength = -depth_strength
            
            # 2. ğŸ”§ ææ…Œè´ªå©ªæŒ‡æ•°å½±å“
            try:
                fear_greed_index = sentiment_analyzer.get_fear_greed_index()
                fg_strength = 0
                
                if fear_greed_index < 25:  # ææ…ŒåŒºåŸŸ
                    fg_strength = (25 - fear_greed_index) * 0.002  # æœ€å¤§+0.05
                elif fear_greed_index > 75:  # è´ªå©ªåŒºåŸŸ
                    fg_strength = (fear_greed_index - 75) * 0.002  # æœ€å¤§+0.05
                
            except:
                fg_strength = 0
            
            # 3. ğŸ”§ ç¤¾äº¤åª’ä½“æƒ…ç»ªï¼ˆå ä½ç¬¦ï¼Œå¯æ‰©å±•ï¼‰
            try:
                social_sentiment = sentiment_analyzer.get_social_sentiment()
                twitter_sentiment = social_sentiment.get('twitter_sentiment', 0.5)
                social_strength = (twitter_sentiment - 0.5) * 0.02  # æœ€å¤§Â±0.01
            except:
                social_strength = 0
            
            # 4. ç»¼åˆæƒ…ç»ªå¼ºåº¦è®¡ç®—
            # åŸºç¡€æƒ…ç»ªåç¦»ä¸­æ€§çš„ç¨‹åº¦
            base_strength = abs(base_sentiment - 0.5) * 0.1  # æœ€å¤§0.05
            
            # ç»¼åˆæ‰€æœ‰æƒ…ç»ªå› å­
            total_sentiment_strength = (
                base_strength +
                wall_strength +
                depth_strength +
                fg_strength +
                social_strength
            )
            
            # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
            total_sentiment_strength = max(-0.1, min(0.1, total_sentiment_strength))
            
            logging.info(f"   ğŸ“Š æƒ…ç»ªåˆ†æè¯¦æƒ…:")
            logging.info(f"      åŸºç¡€æƒ…ç»ª: {base_sentiment:.3f}")
            logging.info(f"      ä¹°å–å¢™æ¯”: {wall_ratio:.3f} (å¼ºåº¦: {wall_strength:+.3f})")
            logging.info(f"      æ·±åº¦ä¸å¹³è¡¡: {deep_imbalance:+.3f} (å¼ºåº¦: {depth_strength:+.3f})")
            logging.info(f"      ææ…Œè´ªå©ª: {fear_greed_index:.1f} (å¼ºåº¦: {fg_strength:+.3f})")
            
            return total_sentiment_strength
            
        except Exception as e:
            logging.warning(f"âš ï¸ å¢å¼ºæƒ…ç»ªå¼ºåº¦è®¡ç®—å¤±è´¥: {e}")
            return 0

    def calculate_sentiment_strength(self):
        """è®¡ç®—æƒ…ç»ªå¼ºåº¦ï¼Œç”¨äºå¢å¼ºç½®ä¿¡åº¦ - ä¿æŒå‘åå…¼å®¹"""
        return self.calculate_enhanced_sentiment_strength()
    
    def simulate_trade(self, prediction_result):
        """æ¨¡æ‹Ÿäº‹ä»¶åˆçº¦äº¤æ˜“ - ä½¿ç”¨é©¬ä¸æ ¼å°”ç­–ç•¥"""
        if prediction_result is None:
            return
        
        # ä½¿ç”¨é©¬ä¸æ ¼å°”ç­–ç•¥ç¡®å®šæŠ•æ³¨é‡‘é¢
        bet_amount = self.martingale_bet_amounts[self.current_bet_level]
        payout_ratio = self.config['payout_ratio']  # 80%ç›ˆåˆ©ç‡
        
        trade_record = {
            'trade_id': len(self.simulation_records) + 1,
            'timestamp': prediction_result['timestamp'],
            'entry_price': prediction_result['current_price'],
            'prediction': prediction_result['direction'],
            'confidence': prediction_result['confidence'],
            'trade_signal': prediction_result['trade_signal'],
            'bet_amount': bet_amount,
            'bet_level': self.current_bet_level,  # è®°å½•å½“å‰æŠ•æ³¨çº§åˆ«
            'potential_payout': bet_amount * (1 + payout_ratio),  # æœ¬é‡‘ + ç›ˆåˆ© = æ€»å›æŠ¥
            'status': 'OPEN',
            'result_checked': False,
            'profit_loss_amount': 0,
            'result_timestamp': None,
            'exit_price': None,
            'accuracy': None,
            'result': None
        }
        
        # è®¾ç½®10åˆ†é’Ÿåæ£€æŸ¥ç»“æœ
        check_time = prediction_result['timestamp'] + pd.Timedelta(minutes=self.config['prediction_minutes'])
        schedule.every().day.at(check_time.strftime('%H:%M')).do(
            self.check_trade_result, 
            len(self.simulation_records)
        ).tag(f'trade_check_{len(self.simulation_records)}')
        
        self.simulation_records.append(trade_record)
        self.save_simulation_records()
        
        # æ˜¾ç¤ºäº¤æ˜“è®°å½•
        print(f"\n{'='*80}")
        print(f"ğŸ¯ äº‹ä»¶åˆçº¦äº¤æ˜“è®°å½• #{trade_record['trade_id']} - é©¬ä¸æ ¼å°”ç­–ç•¥ (çº§åˆ« {self.current_bet_level})")
        print(f"{'='*80}")
        print(f"â° æŠ•æ³¨æ—¶é—´: {trade_record['timestamp']}")
        print(f"ğŸ’° å½“å‰ä»·æ ¼: ${trade_record['entry_price']:.2f}")
        print(f"ğŸ“Š é¢„æµ‹æ–¹å‘: {trade_record['prediction']}")
        print(f"ğŸ”® äº¤æ˜“ä¿¡å·: {trade_record['trade_signal']}")
        print(f"ğŸ¯ ç½®ä¿¡åº¦: {trade_record['confidence']:.1f}%")
        print(f"ğŸ’µ æŠ•æ³¨é‡‘é¢: {trade_record['bet_amount']} USDT")
        print(f"ğŸ† æ½œåœ¨å›æŠ¥: {trade_record['potential_payout']:.2f} USDT")
        print(f"ğŸ“ˆ äº‹ä»¶åˆçº¦: é¢„æµ‹æ­£ç¡®è·å¾—{trade_record['potential_payout']:.2f}uï¼Œé”™è¯¯å½’é›¶")
        print(f"â³ å°†åœ¨{self.config['prediction_minutes']}åˆ†é’ŸåéªŒè¯ç»“æœ...")
        print(f"{'='*80}\n")
    
    def check_trade_result(self, trade_index):
        """æ£€æŸ¥äº‹ä»¶åˆçº¦äº¤æ˜“ç»“æœ - æ›´æ–°é©¬ä¸æ ¼å°”ç­–ç•¥çŠ¶æ€"""
        if trade_index >= len(self.simulation_records):
            return schedule.CancelJob
        
        trade = self.simulation_records[trade_index]
        if trade['status'] != 'OPEN':
            return schedule.CancelJob
        
        current_price = self.api.get_latest_price(self.config['symbol'])
        if current_price is None:
            logging.error(f"âŒ æ— æ³•è·å–å½“å‰ä»·æ ¼ï¼Œäº¤æ˜“ #{trade_index+1} ç»“æœæ£€æŸ¥å¤±è´¥")
            return schedule.CancelJob
        
        entry_price = trade['entry_price']
        prediction = trade['prediction']
        bet_amount = trade['bet_amount']
        potential_payout = trade['potential_payout']
        
        # åˆ¤æ–­é¢„æµ‹æ˜¯å¦æ­£ç¡®
        actual_direction = 'ä¸Šæ¶¨' if current_price > entry_price else 'ä¸‹è·Œ'
        is_correct = prediction == actual_direction
        
        # è®¡ç®—äº‹ä»¶åˆçº¦ç›ˆäº
        if is_correct:
            # é¢„æµ‹æ­£ç¡®ï¼šè·å¾—å…¨éƒ¨å›æŠ¥
            profit_loss_amount = potential_payout - bet_amount  # å®é™…ç›ˆåˆ© = å›æŠ¥ - æœ¬é‡‘
            final_amount = potential_payout  # æœ€ç»ˆè·å¾—çš„é‡‘é¢
            result = 'WIN'
            
            # èµ¢äº†ï¼Œé‡ç½®ä¸ºåˆå§‹æŠ•æ³¨é¢
            self.current_bet_level = 0
        else:
            # é¢„æµ‹é”™è¯¯ï¼šå¤±å»å…¨éƒ¨æŠ•æ³¨
            profit_loss_amount = -bet_amount  # æŸå¤±å…¨éƒ¨æœ¬é‡‘
            final_amount = 0  # æœ€ç»ˆè·å¾—0
            result = 'LOSS'
            
            # è¾“äº†ï¼Œæé«˜æŠ•æ³¨çº§åˆ«ï¼Œä½†ä¸è¶…è¿‡æœ€å¤§çº§åˆ«
            if self.current_bet_level < len(self.martingale_bet_amounts) - 1:
                self.current_bet_level += 1
            else:
                logging.warning("âš ï¸ å·²è¾¾åˆ°æœ€å¤§æŠ•æ³¨çº§åˆ«ï¼Œé‡ç½®ä¸ºåˆå§‹æŠ•æ³¨")
                self.current_bet_level = 0
        
        # æ›´æ–°äº¤æ˜“è®°å½•
        trade['status'] = 'CLOSED'
        trade['exit_price'] = current_price
        trade['result_timestamp'] = pd.Timestamp.now()
        trade['profit_loss_amount'] = profit_loss_amount
        trade['final_amount'] = final_amount
        trade['result'] = result
        trade['accuracy'] = is_correct
        trade['price_change'] = current_price - entry_price
        trade['price_change_pct'] = (current_price - entry_price) / entry_price * 100
        
        self.simulation_records[trade_index] = trade
        
        # æ˜¾ç¤ºéªŒè¯ç»“æœ
        result_emoji = "ğŸ‰" if result == 'WIN' else "ğŸ’¸"
        result_text = "é¢„æµ‹æ­£ç¡®" if is_correct else "é¢„æµ‹é”™è¯¯"
        
        print(f"\n{'ğŸ°' * 20}")
        print(f"ğŸ“Š äº‹ä»¶åˆçº¦ #{trade_index+1} ç»“ç®—ç»“æœ ğŸ“Š")
        print(f"{'ğŸ°' * 20}")
        print(f"{result_emoji} {result_text}")
        print(f"ğŸ¯ é¢„æµ‹: {prediction} | å®é™…: {actual_direction}")
        print(f"ğŸ’° è¿›åœºä»·æ ¼: ${entry_price:,.2f}")
        print(f"ğŸ’° å‡ºåœºä»·æ ¼: ${current_price:,.2f}")
        print(f"ğŸ“Š ä»·æ ¼å˜åŒ–: {trade['price_change']:+.2f} USDT ({trade['price_change_pct']:+.2f}%)")
        print(f"ğŸ’µ æŠ•æ³¨é‡‘é¢: {bet_amount:.2f} USDT")
        if is_correct:
            print(f"ğŸ† è·å¾—å›æŠ¥: {final_amount:.2f} USDT")
            print(f"ğŸ’° å‡€ç›ˆåˆ©: +{profit_loss_amount:.2f} USDT")
            print(f"ğŸ”„ é©¬ä¸æ ¼å°”ç­–ç•¥: èµ¢äº†ï¼Œä¸‹æ¬¡æŠ•æ³¨å›åˆ° {self.martingale_bet_amounts[self.current_bet_level]} USDT")
        else:
            print(f"ğŸ’¸ å¤±å»æœ¬é‡‘: {bet_amount:.2f} USDT")
            print(f"ğŸ’° å‡€äºæŸ: {profit_loss_amount:.2f} USDT")
            print(f"ğŸ”„ é©¬ä¸æ ¼å°”ç­–ç•¥: è¾“äº†ï¼Œä¸‹æ¬¡æŠ•æ³¨å¢åŠ åˆ° {self.martingale_bet_amounts[self.current_bet_level]} USDT")
        print(f"â° ç»“ç®—æ—¶é—´: {trade['result_timestamp']}")
        print(f"{'ğŸ°' * 20}\n")
        
        # ä¿å­˜äº¤æ˜“è®°å½•
        self.save_simulation_records()
        
        return schedule.CancelJob
    
    def get_total_pnl_stats(self):
        """è·å–æ€»ä½“ç›ˆäºç»Ÿè®¡"""
        if not self.simulation_records:
            return {
                'total_trades': 0,
                'pending_trades': 0,
                'closed_trades': 0,
                'total_invested': 0,
                'total_returned': 0,
                'net_pnl': 0,
                'win_count': 0,
                'loss_count': 0,
                'win_rate': 0,
                'recent_win_rate': 0,
                'avg_win_amount': 0,
                'avg_loss_amount': 0,
                'roi_percentage': 0
            }
        
        closed_trades = [trade for trade in self.simulation_records if trade.get('status', 'CLOSED') == 'CLOSED']
        
        if not closed_trades:
            return {
                'total_trades': len(self.simulation_records),
                'pending_trades': len([t for t in self.simulation_records if t.get('status', 'OPEN') == 'OPEN']),
                'closed_trades': 0,
                'message': 'æš‚æ— å·²å®Œæˆçš„äº¤æ˜“'
            }
        
        # å…¼å®¹æ–°æ—§äº¤æ˜“è®°å½•æ ¼å¼
        total_trades = len(closed_trades)
        total_invested = 0
        total_returned = 0
        
        for trade in closed_trades:
            # å…¼å®¹æ—§è®°å½•æ ¼å¼
            if 'bet_amount' in trade:
                # æ–°æ ¼å¼ï¼šäº‹ä»¶åˆçº¦
                total_invested += trade['bet_amount']
                total_returned += trade.get('final_amount', 0)
            else:
                # æ—§æ ¼å¼ï¼šä¼ ç»Ÿäº¤æ˜“ï¼Œè½¬æ¢ä¸ºäº‹ä»¶åˆçº¦æ ¼å¼
                bet_amount = 5  # é»˜è®¤æŠ•æ³¨é¢
                total_invested += bet_amount
                if trade.get('result') == 'WIN' or trade.get('profit_loss_amount', 0) > 0:
                    total_returned += bet_amount * 1.8  # 9 USDTå›æŠ¥
                # å¦‚æœæ˜¯è¾“ï¼Œtotal_returned += 0ï¼ˆä»€ä¹ˆéƒ½ä¸åŠ ï¼‰
        
        net_pnl = total_returned - total_invested
        
        # ç»Ÿè®¡èƒœè´Ÿ
        win_trades = []
        loss_trades = []
        
        for trade in closed_trades:
            if 'result' in trade:
                # æ–°æ ¼å¼
                if trade['result'] == 'WIN':
                    win_trades.append(trade)
                else:
                    loss_trades.append(trade)
            else:
                # æ—§æ ¼å¼ - æ ¹æ®profit_loss_amountåˆ¤æ–­
                if trade.get('profit_loss_amount', 0) > 0:
                    win_trades.append(trade)
                else:
                    loss_trades.append(trade)
        
        win_count = len(win_trades)
        loss_count = len(loss_trades)
        win_rate = win_count / total_trades if total_trades > 0 else 0
        
        # è®¡ç®—å¹³å‡ç›ˆäº
        avg_win_amount = 0
        avg_loss_amount = 0
        
        if win_count > 0:
            win_amounts = []
            for trade in win_trades:
                if 'bet_amount' in trade and 'profit_loss_amount' in trade:
                    # æ–°æ ¼å¼ï¼šäº‹ä»¶åˆçº¦
                    win_amounts.append(trade['profit_loss_amount'])
                else:
                    # æ—§æ ¼å¼ï¼šç»Ÿä¸€è½¬æ¢ä¸ºäº‹ä»¶åˆçº¦ç›ˆåˆ©
                    win_amounts.append(4)  # äº‹ä»¶åˆçº¦ç›ˆåˆ©4 USDT
            avg_win_amount = sum(win_amounts) / len(win_amounts)
        
        if loss_count > 0:
            loss_amounts = []
            for trade in loss_trades:
                if 'bet_amount' in trade and 'profit_loss_amount' in trade:
                    # æ–°æ ¼å¼ï¼šäº‹ä»¶åˆçº¦
                    loss_amounts.append(trade['profit_loss_amount'])
                else:
                    # æ—§æ ¼å¼ï¼šç»Ÿä¸€è½¬æ¢ä¸ºäº‹ä»¶åˆçº¦äºæŸ
                    loss_amounts.append(-5)  # äº‹ä»¶åˆçº¦äºæŸ5 USDT
            avg_loss_amount = sum(loss_amounts) / len(loss_amounts)
        
        # æœ€è¿‘äº¤æ˜“ç»Ÿè®¡
        recent_trades = closed_trades[-10:] if len(closed_trades) >= 10 else closed_trades
        recent_win_count = 0
        for trade in recent_trades:
            if 'result' in trade:
                if trade['result'] == 'WIN':
                    recent_win_count += 1
            else:
                if trade.get('profit_loss_amount', 0) > 0:
                    recent_win_count += 1
        
        recent_win_rate = recent_win_count / len(recent_trades) if recent_trades else 0
        
        return {
            'total_trades': total_trades,
            'pending_trades': len([t for t in self.simulation_records if t.get('status', 'OPEN') == 'OPEN']),
            'total_invested': total_invested,
            'total_returned': total_returned,
            'net_pnl': net_pnl,
            'win_count': win_count,
            'loss_count': loss_count,
            'win_rate': win_rate,
            'recent_win_rate': recent_win_rate,
            'avg_win_amount': avg_win_amount,
            'avg_loss_amount': avg_loss_amount,
            'roi_percentage': (net_pnl / total_invested * 100) if total_invested > 0 else 0
        }
    
    def display_pnl_stats(self):
        """æ˜¾ç¤ºæ€»ä½“ç›ˆäºç»Ÿè®¡"""
        stats = self.get_total_pnl_stats()
        
        if 'message' in stats:
            print(f"\nğŸ“Š äº‹ä»¶åˆçº¦äº¤æ˜“ç»Ÿè®¡")
            print(f"æ€»äº¤æ˜“æ•°: {stats['total_trades']}")
            print(f"å¾…ç»“ç®—: {stats['pending_trades']}")
            print(f"å·²å®Œæˆ: {stats['closed_trades']}")
            print(f"çŠ¶æ€: {stats['message']}")
        else:
            # é¢œè‰²å¤„ç†
            pnl_emoji = "ğŸŸ¢" if stats['net_pnl'] >= 0 else "ğŸ”´"
            pnl_sign = "+" if stats['net_pnl'] >= 0 else ""
            
            print(f"\n{'ğŸ’°' * 25}")
            print(f"ğŸ“Š äº‹ä»¶åˆçº¦äº¤æ˜“æ€»ä½“ç»Ÿè®¡ ğŸ“Š")
            print(f"{'ğŸ’°' * 25}")
            print(f"ğŸ¯ æ€»äº¤æ˜“æ¬¡æ•°: {stats['total_trades']} ç¬”")
            print(f"â³ å¾…ç»“ç®—äº¤æ˜“: {stats['pending_trades']} ç¬”")
            print(f"âœ… æˆåŠŸäº¤æ˜“: {stats['win_count']} ç¬”")
            print(f"âŒ å¤±è´¥äº¤æ˜“: {stats['loss_count']} ç¬”")
            print(f"ğŸ“ˆ æ•´ä½“èƒœç‡: {stats['win_rate']:.1%}")
            print(f"ğŸ“ˆ è¿‘æœŸèƒœç‡: {stats['recent_win_rate']:.1%} (æœ€è¿‘10ç¬”)")
            print(f"{'â”€' * 50}")
            print(f"ğŸ’µ æ€»æŠ•æ³¨é‡‘é¢: {stats['total_invested']} USDT")
            print(f"ğŸ’° æ€»å›æ”¶é‡‘é¢: {stats['total_returned']} USDT")
            print(f"{pnl_emoji} å‡€ç›ˆäº: {pnl_sign}{stats['net_pnl']} USDT")
            print(f"ğŸ“Š æŠ•èµ„å›æŠ¥ç‡: {pnl_sign}{stats['roi_percentage']:.2f}%")
            print(f"{'â”€' * 50}")
            print(f"ğŸ† å¹³å‡å•ç¬”ç›ˆåˆ©: +{stats['avg_win_amount']:.2f} USDT")
            print(f"ğŸ’¸ å¹³å‡å•ç¬”äºæŸ: {stats['avg_loss_amount']:.2f} USDT")
            print(f"{'ğŸ’°' * 25}")
        
        # æ·»åŠ è¿”å›æœºåˆ¶
        print(f"\n{'ğŸ”™' * 20}")
        print("ğŸ“Œ æŒ‰ä»»æ„é”®è¿”å›ç›‘æ§çŠ¶æ€...")
        print(f"{'ğŸ”™' * 20}")
        
        # ç­‰å¾…ç”¨æˆ·æŒ‰é”®
        if sys.platform == 'win32':
            import msvcrt
            msvcrt.getch()  # Windowsä¸‹ç­‰å¾…æŒ‰é”®
        else:
            import termios, tty
            fd = sys.stdin.fileno()
            old_settings = termios.tcgetattr(fd)
            try:
                tty.cbreak(fd)
                sys.stdin.read(1)  # Linux/Macä¸‹ç­‰å¾…æŒ‰é”®
            finally:
                termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
        
        print("ğŸ”„ è¿”å›ç›‘æ§çŠ¶æ€...\n")
    
    def calculate_performance(self):
        """è®¡ç®—ç»©æ•ˆ - é€‚é…äº‹ä»¶åˆçº¦"""
        stats = self.get_total_pnl_stats()
        
        if 'message' in stats:
            logging.info("ğŸ“Š æš‚æ— å·²å®Œæˆçš„äº¤æ˜“ï¼Œæ— æ³•è®¡ç®—ç»©æ•ˆ")
            return stats
        
        logging.info(f"ğŸ“Š äº‹ä»¶åˆçº¦ç»©æ•ˆæŠ¥å‘Š:")
        logging.info(f"   æ€»äº¤æ˜“æ¬¡æ•°: {stats['total_trades']}")
        logging.info(f"   èƒœç‡: {stats['win_rate']:.2%}")
        logging.info(f"   å‡€ç›ˆäº: {stats['net_pnl']:+.2f} USDT")
        logging.info(f"   æŠ•èµ„å›æŠ¥ç‡: {stats['roi_percentage']:+.2f}%")
        
        return stats
    
    def save_simulation_records(self):
        with open('simulation_records.json', 'w') as f:
            json.dump(self.simulation_records, f, indent=4, default=str)
    
    def load_simulation_records(self):
        if os.path.exists('simulation_records.json'):
            try:
                with open('simulation_records.json', 'r') as f:
                    self.simulation_records = json.load(f)
                logging.info(f"åŠ è½½äº† {len(self.simulation_records)} æ¡äº¤æ˜“è®°å½•")
            except Exception as e:
                logging.error(f"åŠ è½½äº¤æ˜“è®°å½•æ—¶å‡ºé”™: {e}")
    
    def plot_performance(self):
        if not self.simulation_records:
            logging.info("æ²¡æœ‰äº¤æ˜“è®°å½•ï¼Œæ— æ³•ç»˜åˆ¶ç»©æ•ˆå›¾è¡¨")
            return
        
        closed_trades = [trade for trade in self.simulation_records if trade['status'] == 'CLOSED']
        if not closed_trades:
            logging.info("æ²¡æœ‰å·²å®Œæˆçš„äº¤æ˜“ï¼Œæ— æ³•ç»˜åˆ¶ç»©æ•ˆå›¾è¡¨")
            return
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(closed_trades)
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df['exit_time'] = pd.to_datetime(df['exit_time'])
        df = df.sort_values('timestamp')
        
        # è®¡ç®—ç´¯è®¡ç›ˆäº
        df['cumulative_profit_loss'] = df['profit_loss'].cumsum()
        
        # è®¾ç½®é¢œè‰²ä¸»é¢˜
        plt.style.use('dark_background')
        green_color = '#00FF7F'  # ç»¿è‰²
        red_color = '#FF5555'    # çº¢è‰²
        blue_color = '#00BFFF'   # è“è‰²
        yellow_color = '#FFD700' # é»„è‰²
        purple_color = '#BA55D3' # ç´«è‰²
        
        # åˆ›å»ºå­å›¾
        fig = plt.figure(figsize=(16, 12))
        gs = fig.add_gridspec(3, 2)
        
        # 1. ç´¯è®¡ç›ˆäºæ›²çº¿ (å·¦ä¸Š)
        ax1 = fig.add_subplot(gs[0, 0])
        ax1.plot(df['exit_time'], df['cumulative_profit_loss'], color=blue_color, linewidth=2)
        ax1.fill_between(df['exit_time'], df['cumulative_profit_loss'], 0, 
                         where=(df['cumulative_profit_loss'] >= 0), color=green_color, alpha=0.3)
        ax1.fill_between(df['exit_time'], df['cumulative_profit_loss'], 0, 
                         where=(df['cumulative_profit_loss'] < 0), color=red_color, alpha=0.3)
        ax1.set_title('ç´¯è®¡ç›ˆäº (%)', fontsize=14, fontweight='bold')
        ax1.grid(True, alpha=0.3)
        ax1.axhline(y=0, color='gray', linestyle='--', alpha=0.7)
        
        # 2. æ¯ç¬”äº¤æ˜“ç›ˆäº (å³ä¸Š)
        ax2 = fig.add_subplot(gs[0, 1])
        colors = [green_color if pl > 0 else red_color for pl in df['profit_loss']]
        ax2.bar(range(len(df)), df['profit_loss'], color=colors, alpha=0.7)
        ax2.set_title('æ¯ç¬”äº¤æ˜“ç›ˆäº (%)', fontsize=14, fontweight='bold')
        ax2.set_xlabel('äº¤æ˜“ç¼–å·')
        ax2.set_ylabel('ç›ˆäº (%)')
        ax2.grid(True, alpha=0.3)
        ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.7)
        
        # 3. èƒœç‡ç»Ÿè®¡é¥¼å›¾ (å·¦ä¸­)
        ax3 = fig.add_subplot(gs[1, 0])
        win_count = sum(1 for trade in closed_trades if trade['result'] == 'WIN')
        loss_count = len(closed_trades) - win_count
        ax3.pie([win_count, loss_count], 
                labels=['ç›ˆåˆ©', 'äºæŸ'], 
                colors=[green_color, red_color],
                autopct='%1.1f%%', 
                startangle=90,
                wedgeprops={'alpha': 0.7})
        ax3.set_title('äº¤æ˜“èƒœç‡ç»Ÿè®¡', fontsize=14, fontweight='bold')
        
        # 4. ç›ˆäºåˆ†å¸ƒç›´æ–¹å›¾ (å³ä¸­)
        ax4 = fig.add_subplot(gs[1, 1])
        ax4.hist(df['profit_loss'], bins=20, color=blue_color, alpha=0.7)
        ax4.set_title('ç›ˆäºåˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax4.set_xlabel('ç›ˆäº (%)')
        ax4.set_ylabel('é¢‘ç‡')
        ax4.grid(True, alpha=0.3)
        ax4.axvline(x=0, color='gray', linestyle='--', alpha=0.7)
        
        # 5. ä¿¡å¿ƒåº¦ä¸ç›ˆäºå…³ç³»æ•£ç‚¹å›¾ (åº•éƒ¨è·¨åˆ—)
        ax5 = fig.add_subplot(gs[2, :])
        scatter = ax5.scatter(df['confidence'], df['profit_loss'], 
                              c=df['profit_loss'], cmap='coolwarm', 
                              s=100, alpha=0.7)
        ax5.set_title('ç½®ä¿¡åº¦ä¸ç›ˆäºå…³ç³»', fontsize=14, fontweight='bold')
        ax5.set_xlabel('ç½®ä¿¡åº¦')
        ax5.set_ylabel('ç›ˆäº (%)')
        ax5.grid(True, alpha=0.3)
        ax5.axhline(y=0, color='gray', linestyle='--', alpha=0.7)
        fig.colorbar(scatter, ax=ax5)
        
        # æ·»åŠ ç»Ÿè®¡æ•°æ®æ–‡æœ¬æ¡†
        win_rate = win_count / len(closed_trades) if closed_trades else 0
        avg_profit = sum(trade['profit_loss'] for trade in closed_trades if trade['profit_loss'] > 0) / win_count if win_count else 0
        avg_loss = sum(trade['profit_loss'] for trade in closed_trades if trade['profit_loss'] <= 0) / loss_count if loss_count else 0
        total_pl = sum(trade['profit_loss'] for trade in closed_trades)
        
        stats_text = f"æ€»äº¤æ˜“æ¬¡æ•°: {len(closed_trades)}\n"
        stats_text += f"èƒœç‡: {win_rate:.2%}\n"
        stats_text += f"å¹³å‡ç›ˆåˆ©: {avg_profit:.2f}%\n"
        stats_text += f"å¹³å‡äºæŸ: {avg_loss:.2f}%\n"
        stats_text += f"æ€»ç›ˆäº: {total_pl:.2f}%"
        
        # åœ¨å›¾è¡¨ç©ºç™½å¤„æ·»åŠ ç»Ÿè®¡æ–‡æœ¬
        plt.figtext(0.92, 0.5, stats_text, 
                   bbox=dict(facecolor='gray', alpha=0.1),
                   fontsize=12, ha='right')
        
        # æ·»åŠ æ ‡é¢˜å’Œæ—¶é—´æˆ³
        plt.suptitle('æ¯”ç‰¹å¸ä»·æ ¼é¢„æµ‹äº¤æ˜“ç³»ç»Ÿç»©æ•ˆåˆ†æ', fontsize=18, fontweight='bold')
        plt.figtext(0.5, 0.01, f'ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}', 
                   ha='center', fontsize=10)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.92)
        plt.savefig('performance.png', dpi=300)
        logging.info("ç»©æ•ˆå›¾è¡¨å·²ä¿å­˜è‡³ performance.png")
        
        # é¢å¤–ç”Ÿæˆç­–ç•¥æ•ˆæœå›¾
        self.plot_strategy_performance(df)
    
    def plot_strategy_performance(self, df):
        """ç»˜åˆ¶ç­–ç•¥æ•ˆæœå¯¹æ¯”å›¾"""
        plt.style.use('dark_background')
        
        # åˆ›å»ºå›¾è¡¨
        fig, ax = plt.subplots(figsize=(14, 8))
        
        # è·å–ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªäº¤æ˜“æ—¶é—´ç‚¹
        start_time = df['timestamp'].min()
        end_time = df['exit_time'].max()
        
        # é‡æ–°ä»å¸å®‰è·å–è¿™æ®µæ—¶é—´çš„æ¯”ç‰¹å¸ä»·æ ¼æ•°æ®
        try:
            lookback_time = start_time.strftime("%d %b, %Y")
            klines = self.api.get_multi_timeframe_data(
                self.config['symbol'], 
                self.config['intervals'], 
                lookback_time
            )
            
            if klines:
                # è½¬æ¢ä¸ºDataFrame
                price_df = pd.DataFrame(klines['1m'], columns=[
                    'open_time', 'open', 'high', 'low', 'close', 'volume',
                    'close_time', 'quote_asset_volume', 'number_of_trades',
                    'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'
                ])
                
                # è½¬æ¢æ•°æ®ç±»å‹
                price_df['open_time'] = pd.to_datetime(price_df['open_time'], unit='ms')
                price_df['close'] = pd.to_numeric(price_df['close'])
                
                # ç­›é€‰æ—¥æœŸèŒƒå›´
                price_df = price_df[(price_df['open_time'] >= start_time) & (price_df['open_time'] <= end_time)]
                
                if not price_df.empty:
                    # è®¡ç®—ä»·æ ¼å˜åŒ–ç™¾åˆ†æ¯”
                    initial_price = price_df['close'].iloc[0]
                    price_df['price_change_pct'] = (price_df['close'] / initial_price - 1) * 100
                    
                    # ç»˜åˆ¶ä»·æ ¼å˜åŒ–æ›²çº¿
                    ax.plot(price_df['open_time'], price_df['price_change_pct'], 
                            color='gray', alpha=0.7, label='BTCä»·æ ¼å˜åŒ–(%)')
                    
                    # ç»˜åˆ¶ç­–ç•¥æ›²çº¿
                    ax.plot(df['exit_time'], df['cumulative_profit_loss'], 
                            color='#00BFFF', linewidth=2, label='ç­–ç•¥ç´¯è®¡æ”¶ç›Š(%)')
                    
                    # ç»˜åˆ¶ä¹°å…¥ç‚¹å’Œå–å‡ºç‚¹
                    for _, trade in df.iterrows():
                        marker = '^' if trade['position'] == 'LONG' else 'v'
                        color = 'green' if trade['result'] == 'WIN' else 'red'
                        ax.scatter(trade['timestamp'], 0, marker=marker, color=color, s=100, alpha=0.7)
                    
                    # è®¾ç½®å›¾è¡¨
                    ax.set_title('ç­–ç•¥æ”¶ç›Šä¸BTCä»·æ ¼å¯¹æ¯”', fontsize=16, fontweight='bold')
                    ax.set_xlabel('æ—¶é—´')
                    ax.set_ylabel('æ”¶ç›Šç‡ (%)')
                    ax.grid(True, alpha=0.3)
                    ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
                    ax.legend()
                    
                    # æ·»åŠ æ ‡æ³¨
                    plt.figtext(0.5, 0.01, 'ç»¿è‰²ä¸‰è§’å½¢:ç›ˆåˆ©äº¤æ˜“  çº¢è‰²ä¸‰è§’å½¢:äºæŸäº¤æ˜“  å‘ä¸Šä¸‰è§’:åšå¤š  å‘ä¸‹ä¸‰è§’:åšç©º', 
                              ha='center', fontsize=10)
                    
                    plt.tight_layout()
                    plt.savefig('strategy_performance.png', dpi=300)
                    logging.info("ç­–ç•¥å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜è‡³ strategy_performance.png")
        except Exception as e:
            logging.error(f"ç»˜åˆ¶ç­–ç•¥å¯¹æ¯”å›¾è¡¨æ—¶å‡ºé”™: {e}")
    
    def backtest(self, start_date=None, end_date=None, period_days=30):
        """
        å¯¹å†å²æ•°æ®è¿›è¡Œå›æµ‹ï¼ŒéªŒè¯æ¨¡å‹é¢„æµ‹å‡†ç¡®ç‡
        
        å‚æ•°:
            start_date: å›æµ‹å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼: 'YYYY-MM-DD'
            end_date: å›æµ‹ç»“æŸæ—¥æœŸï¼Œæ ¼å¼: 'YYYY-MM-DD'
            period_days: å¦‚æœæœªæŒ‡å®šæ—¥æœŸï¼Œå›æµ‹æœ€è¿‘çš„å¤©æ•°
        """
        if self.model is None:
            logging.error("æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œå›æµ‹")
            return
        
        # è®¾ç½®å›æµ‹æ—¥æœŸèŒƒå›´
        if start_date is None:
            start_time = (datetime.now() - timedelta(days=period_days)).strftime("%d %b, %Y")
        else:
            start_time = datetime.strptime(start_date, "%Y-%m-%d").strftime("%d %b, %Y")
        
        if end_date is None:
            end_time = datetime.now().strftime("%d %b, %Y")
        else:
            end_time = datetime.strptime(end_date, "%Y-%m-%d").strftime("%d %b, %Y")
        
        logging.info(f"å¼€å§‹å›æµ‹ - æ—¶é—´èŒƒå›´: {start_time} åˆ° {end_time}")
        
        try:
            # è·å–å†å²Kçº¿æ•°æ®
            klines = self.api.get_multi_timeframe_data(
                self.config['symbol'], 
                self.config['intervals'], 
                start_time
            )
            
            if not klines or len(klines['1m']) < 100:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
                logging.error(f"å›æµ‹æ•°æ®ä¸è¶³ï¼Œè·å–åˆ° {len(klines['1m']) if klines['1m'] else 0} æ¡è®°å½•")
                return
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(klines['1m'], columns=[
                'open_time', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_asset_volume', 'number_of_trades',
                'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'
            ])
            
            # è½¬æ¢æ•°æ®ç±»å‹
            df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')
            df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')
            numeric_columns = ['open', 'high', 'low', 'close', 'volume', 
                            'quote_asset_volume', 'number_of_trades',
                            'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']
            df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric)
            
            # åˆ›å»ºæŠ€æœ¯æŒ‡æ ‡
            df = self.data_processor.add_enhanced_technical_indicators(df, '1m')
            
            # ä¸¢å¼ƒNaNå€¼
            df = df.dropna().reset_index(drop=True)
            
            # å‡†å¤‡å›æµ‹æ•°æ®
            total_samples = len(df) - self.config['prediction_minutes']
            backtest_results = []
            
            logging.info(f"å¼€å§‹å›æµ‹ {total_samples} ä¸ªæ—¶é—´ç‚¹...")
            
            # å›æµ‹æ¯ä¸ªæ—¶é—´ç‚¹
            for i in range(0, total_samples, 10):  # æ¯10ä¸ªæ—¶é—´ç‚¹é‡‡æ ·ä¸€æ¬¡ï¼Œæé«˜æ•ˆç‡
                if i % 100 == 0:
                    logging.info(f"å›æµ‹è¿›åº¦: {i}/{total_samples}")
                
                # è·å–å½“å‰æ—¶é—´ç‚¹çš„æ•°æ®
                current_data = df.iloc[:i + self.config['prediction_minutes']]
                
                # å‡†å¤‡ç‰¹å¾æ•°æ®
                features = current_data[self.data_processor.features].values
                if len(features) < 10:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„åºåˆ—é•¿åº¦
                    continue
                
                # å½’ä¸€åŒ–ç‰¹å¾
                features_scaled = self.data_processor.feature_scalers['1m'].transform(features)
                
                # åˆ›å»ºåºåˆ—
                X = []
                seq_length = 10
                if len(features_scaled) <= seq_length:
                    continue
                    
                X.append(features_scaled[-seq_length:])
                X = torch.FloatTensor(np.array(X))
                
                # é¢„æµ‹
                self.model.eval()
                with torch.no_grad():
                    X_tensor = X.to(self.device)
                    prediction = self.model(X_tensor)
                    probability = prediction.item()
                
                # è·å–å½“å‰ä»·æ ¼å’Œæœªæ¥ä»·æ ¼
                current_price = float(current_data['close'].iloc[-1])
                future_price = float(df['close'].iloc[i + self.config['prediction_minutes']])
                
                # ç¡®å®šé¢„æµ‹ç»“æœ
                predicted_direction = 'UP' if probability >= self.config['threshold'] else 'DOWN'
                actual_direction = 'UP' if future_price > current_price else 'DOWN'
                is_correct = predicted_direction == actual_direction
                confidence = abs(probability - 0.5) * 2  # 0-1ä¹‹é—´çš„ç½®ä¿¡åº¦
                
                # è®¡ç®—ä»·æ ¼å˜åŒ–
                price_change_pct = (future_price - current_price) / current_price * 100
                
                # è®¡ç®—å›æµ‹ç›ˆäº
                if predicted_direction == 'UP':
                    pnl = price_change_pct  # åšå¤šçš„ç›ˆäº
                else:
                    pnl = -price_change_pct  # åšç©ºçš„ç›ˆäº
                
                # è®°å½•ç»“æœ
                result = {
                    'timestamp': current_data['open_time'].iloc[-1],
                    'current_price': current_price,
                    'future_price': future_price,
                    'prediction': predicted_direction,
                    'actual': actual_direction,
                    'probability': probability,
                    'confidence': confidence,
                    'is_correct': is_correct,
                    'price_change_pct': price_change_pct,
                    'pnl': pnl
                }
                
                backtest_results.append(result)
            
            # è®¡ç®—å›æµ‹ç»Ÿè®¡
            if not backtest_results:
                logging.error("å›æµ‹ç»“æœä¸ºç©º")
                return
                
            backtest_df = pd.DataFrame(backtest_results)
            
            # åŸºæœ¬ç»Ÿè®¡
            total_trades = len(backtest_df)
            correct_trades = sum(backtest_df['is_correct'])
            accuracy = correct_trades / total_trades if total_trades > 0 else 0
            
            # æŒ‰ç½®ä¿¡åº¦åˆ†å±‚åˆ†æ
            backtest_df['confidence_bin'] = pd.cut(backtest_df['confidence'], 
                                                 bins=[0, 0.2, 0.4, 0.6, 0.8, 1.0],
                                                 labels=['0-0.2', '0.2-0.4', '0.4-0.6', '0.6-0.8', '0.8-1.0'])
            
            confidence_stats = backtest_df.groupby('confidence_bin').agg({
                'is_correct': ['count', 'mean'],
                'pnl': ['mean', 'sum', 'std']
            })
            
            # è®¡ç®—ç´¯è®¡æ”¶ç›Š
            backtest_df['cumulative_pnl'] = backtest_df['pnl'].cumsum()
            
            # è¾“å‡ºå›æµ‹ç»“æœ
            logging.info("\n" + "="*50)
            logging.info("å›æµ‹ç»“æœæ‘˜è¦:")
            logging.info(f"å›æµ‹æ—¶é—´èŒƒå›´: {backtest_df['timestamp'].min()} åˆ° {backtest_df['timestamp'].max()}")
            logging.info(f"æ€»æ ·æœ¬æ•°: {total_trades}")
            logging.info(f"æ€»ä½“å‡†ç¡®ç‡: {accuracy:.4f}")
            logging.info(f"å¹³å‡æ”¶ç›Šç‡: {backtest_df['pnl'].mean():.4f}%")
            logging.info(f"ç´¯è®¡æ”¶ç›Šç‡: {backtest_df['pnl'].sum():.4f}%")
            logging.info(f"æœ€å¤§å•æ¬¡æ”¶ç›Š: {backtest_df['pnl'].max():.4f}%")
            logging.info(f"æœ€å¤§å•æ¬¡äºæŸ: {backtest_df['pnl'].min():.4f}%")
            logging.info(f"æ”¶ç›Šæ ‡å‡†å·®: {backtest_df['pnl'].std():.4f}%")
            logging.info("="*50)
            
            # ç»˜åˆ¶å›æµ‹å›¾è¡¨
            self.plot_backtest_results(backtest_df)
            
            # è¿”å›å›æµ‹ç»“æœ
            return backtest_df
            
        except Exception as e:
            logging.error(f"å›æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return None
    
    def plot_backtest_results(self, backtest_df):
        """ç»˜åˆ¶å›æµ‹ç»“æœå›¾è¡¨"""
        plt.style.use('dark_background')
        
        # åˆ›å»ºå›¾è¡¨å¸ƒå±€
        fig = plt.figure(figsize=(16, 14))
        gs = fig.add_gridspec(4, 2)
        
        # è®¾ç½®é¢œè‰²
        blue_color = '#00BFFF'   # è“è‰²
        green_color = '#00FF7F'  # ç»¿è‰²
        red_color = '#FF5555'    # çº¢è‰²
        yellow_color = '#FFD700' # é»„è‰²
        
        # 1. ä»·æ ¼ä¸é¢„æµ‹ (é¡¶éƒ¨è·¨ä¸¤åˆ—)
        ax1 = fig.add_subplot(gs[0, :])
        ax1.plot(backtest_df['timestamp'], backtest_df['current_price'], color='gray', alpha=0.7, label='BTCä»·æ ¼')
        
        # æ ‡è®°æ­£ç¡®å’Œé”™è¯¯çš„é¢„æµ‹
        correct_df = backtest_df[backtest_df['is_correct']]
        incorrect_df = backtest_df[~backtest_df['is_correct']]
        
        # ä¸Šæ¶¨é¢„æµ‹
        up_correct = correct_df[correct_df['prediction'] == 'UP']
        up_incorrect = incorrect_df[incorrect_df['prediction'] == 'UP']
        
        # ä¸‹è·Œé¢„æµ‹
        down_correct = correct_df[correct_df['prediction'] == 'DOWN']
        down_incorrect = incorrect_df[incorrect_df['prediction'] == 'DOWN']
        
        # ç»˜åˆ¶é¢„æµ‹ç‚¹
        ax1.scatter(up_correct['timestamp'], up_correct['current_price'], 
                   color=green_color, marker='^', s=50, alpha=0.7, label='æ­£ç¡®ä¸Šæ¶¨é¢„æµ‹')
        ax1.scatter(down_correct['timestamp'], down_correct['current_price'], 
                   color=green_color, marker='v', s=50, alpha=0.7, label='æ­£ç¡®ä¸‹è·Œé¢„æµ‹')
        ax1.scatter(up_incorrect['timestamp'], up_incorrect['current_price'], 
                   color=red_color, marker='^', s=50, alpha=0.7, label='é”™è¯¯ä¸Šæ¶¨é¢„æµ‹')
        ax1.scatter(down_incorrect['timestamp'], down_incorrect['current_price'], 
                   color=red_color, marker='v', s=50, alpha=0.7, label='é”™è¯¯ä¸‹è·Œé¢„æµ‹')
        
        ax1.set_title('BTCä»·æ ¼ä¸é¢„æµ‹ç‚¹', fontsize=14, fontweight='bold')
        ax1.set_ylabel('ä»·æ ¼')
        ax1.grid(True, alpha=0.3)
        ax1.legend()
        
        # 2. ç´¯è®¡æ”¶ç›Š (ç¬¬äºŒè¡Œå·¦)
        ax2 = fig.add_subplot(gs[1, 0])
        ax2.plot(backtest_df['timestamp'], backtest_df['cumulative_pnl'], color=blue_color, linewidth=2)
        ax2.fill_between(backtest_df['timestamp'], backtest_df['cumulative_pnl'], 0, 
                         where=(backtest_df['cumulative_pnl'] >= 0), color=green_color, alpha=0.3)
        ax2.fill_between(backtest_df['timestamp'], backtest_df['cumulative_pnl'], 0, 
                         where=(backtest_df['cumulative_pnl'] < 0), color=red_color, alpha=0.3)
        ax2.set_title('å›æµ‹ç´¯è®¡æ”¶ç›Š (%)', fontsize=14, fontweight='bold')
        ax2.grid(True, alpha=0.3)
        ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.7)
        
        # 3. æ¯æ¬¡é¢„æµ‹æ”¶ç›Š (ç¬¬äºŒè¡Œå³)
        ax3 = fig.add_subplot(gs[1, 1])
        colors = [green_color if pnl > 0 else red_color for pnl in backtest_df['pnl']]
        ax3.bar(range(len(backtest_df)), backtest_df['pnl'], color=colors, alpha=0.7)
        ax3.set_title('æ¯æ¬¡é¢„æµ‹æ”¶ç›Š (%)', fontsize=14, fontweight='bold')
        ax3.set_xlabel('é¢„æµ‹åºå·')
        ax3.grid(True, alpha=0.3)
        ax3.axhline(y=0, color='gray', linestyle='--', alpha=0.7)
        
        # 4. ç½®ä¿¡åº¦åˆ†å¸ƒä¸å‡†ç¡®ç‡ (ç¬¬ä¸‰è¡Œå·¦)
        ax4 = fig.add_subplot(gs[2, 0])
        confidence_groups = backtest_df.groupby('confidence_bin')
        
        conf_bins = []
        accuracies = []
        counts = []
        
        for conf_bin, group in confidence_groups:
            if not conf_bin or pd.isna(conf_bin):
                continue
                
            conf_bins.append(conf_bin)
            accuracies.append(group['is_correct'].mean())
            counts.append(len(group))
        
        # ç»˜åˆ¶ç½®ä¿¡åº¦ä¸å‡†ç¡®ç‡å…³ç³»
        bars = ax4.bar(conf_bins, accuracies, color=blue_color, alpha=0.7)
        
        # æ·»åŠ äº¤æ˜“æ¬¡æ•°æ ‡ç­¾
        for i, bar in enumerate(bars):
            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, 
                    f'n={counts[i]}', ha='center', va='bottom', fontsize=9)
        
        ax4.set_title('ç½®ä¿¡åº¦ä¸å‡†ç¡®ç‡å…³ç³»', fontsize=14, fontweight='bold')
        ax4.set_xlabel('ç½®ä¿¡åº¦åŒºé—´')
        ax4.set_ylabel('å‡†ç¡®ç‡')
        ax4.set_ylim(0, 1)
        ax4.grid(True, alpha=0.3)
        
        # 5. æ”¶ç›Šåˆ†å¸ƒç›´æ–¹å›¾ (ç¬¬ä¸‰è¡Œå³)
        ax5 = fig.add_subplot(gs[2, 1])
        ax5.hist(backtest_df['pnl'], bins=30, color=blue_color, alpha=0.7)
        ax5.axvline(x=0, color='gray', linestyle='--', alpha=0.7)
        ax5.set_title('æ”¶ç›Šåˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax5.set_xlabel('æ”¶ç›Šç‡ (%)')
        ax5.grid(True, alpha=0.3)
        
        # 6. ç½®ä¿¡åº¦ä¸æ”¶ç›Šå…³ç³»æ•£ç‚¹å›¾ (ç¬¬å››è¡Œè·¨åˆ—)
        ax6 = fig.add_subplot(gs[3, :])
        scatter = ax6.scatter(backtest_df['confidence'], backtest_df['pnl'], 
                             c=backtest_df['pnl'], cmap='coolwarm', 
                             s=80, alpha=0.7)
        ax6.set_title('ç½®ä¿¡åº¦ä¸æ”¶ç›Šå…³ç³»', fontsize=14, fontweight='bold')
        ax6.set_xlabel('ç½®ä¿¡åº¦')
        ax6.set_ylabel('æ”¶ç›Šç‡ (%)')
        ax6.grid(True, alpha=0.3)
        ax6.axhline(y=0, color='gray', linestyle='--', alpha=0.7)
        fig.colorbar(scatter, ax=ax6)
        
        # æ·»åŠ ç»Ÿè®¡æ•°æ®æ–‡æœ¬æ¡†
        stats_text = f"æ€»æ ·æœ¬æ•°: {len(backtest_df)}\n"
        stats_text += f"æ€»ä½“å‡†ç¡®ç‡: {backtest_df['is_correct'].mean():.2%}\n"
        stats_text += f"å¹³å‡æ”¶ç›Šç‡: {backtest_df['pnl'].mean():.2f}%\n"
        stats_text += f"ç´¯è®¡æ”¶ç›Šç‡: {backtest_df['pnl'].sum():.2f}%\n"
        stats_text += f"æœ€ä½³ç½®ä¿¡åº¦é˜ˆå€¼: {conf_bins[np.argmax(accuracies)]}"
        
        plt.figtext(0.92, 0.5, stats_text, 
                   bbox=dict(facecolor='gray', alpha=0.1),
                   fontsize=12, ha='right')
        
        # æ·»åŠ æ ‡é¢˜å’Œæ—¶é—´æˆ³
        plt.suptitle('æ¯”ç‰¹å¸ä»·æ ¼é¢„æµ‹ç³»ç»Ÿå›æµ‹ç»“æœ', fontsize=18, fontweight='bold')
        plt.figtext(0.5, 0.01, f'ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}', 
                   ha='center', fontsize=10)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.92)
        plt.savefig('backtest_results.png', dpi=300)
        logging.info("å›æµ‹ç»“æœå›¾è¡¨å·²ä¿å­˜è‡³ backtest_results.png")

    def continuous_predict_and_trade(self):
        """å®æ—¶ç›‘æ§æ¨¡å¼ - ä¿æŒå®Œæ•´é¢„æµ‹å‡†ç¡®ç‡çš„åŒæ—¶ä¼˜åŒ–å“åº”é€Ÿåº¦"""
        last_price = None
        last_prediction_time = None
        loop_count = 0
        last_trade_time = None
        
        print(f"\n{'ğŸš€' * 50}")
        print(f"ğŸ¯ å¯åŠ¨å®æ—¶ç›‘æ§æ¨¡å¼ - å®Œæ•´é¢„æµ‹ç³»ç»Ÿ")
        print(f"ğŸ’¡ æŒç»­ç›‘æ§ä»·æ ¼å˜åŒ–ï¼Œå®Œæ•´æŠ€æœ¯åˆ†æï¼Œå‘ç°é«˜ç½®ä¿¡åº¦äº¤æ˜“æœºä¼šç«‹å³æé†’")
        print(f"ğŸ”§ ä¿æŒæ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡å’Œæƒ…ç»ªåˆ†æï¼Œç¡®ä¿æœ€é«˜é¢„æµ‹å‡†ç¡®ç‡")
        print(f"ğŸ’° é©¬ä¸æ ¼å°”æŠ•æ³¨ç­–ç•¥: åˆå§‹5Uï¼Œè¾“åˆ™ç¿»å€(10Uâ†’30Uâ†’90Uâ†’250U)ï¼Œèµ¢åˆ™å›åˆ°5U")
        print(f"âš¡ æŒ‰ 's' æŸ¥çœ‹ç»Ÿè®¡ | æŒ‰ 'q' é€€å‡ºç¨‹åº")
        print(f"{'ğŸš€' * 50}\n")
        
        def check_keyboard_input():
            """æ£€æŸ¥é”®ç›˜è¾“å…¥çš„å‡½æ•°"""
            if sys.platform == 'win32':
                import msvcrt
                if msvcrt.kbhit():
                    key = msvcrt.getch().decode('utf-8').lower()
                    if key == 's':
                        self.display_pnl_stats()
                    elif key == 'q':
                        logging.info("ğŸ‘‹ ç”¨æˆ·é€‰æ‹©é€€å‡ºç¨‹åº")
                        return True
            else:
                # Linux/Macç³»ç»Ÿçš„éé˜»å¡è¾“å…¥æ£€æŸ¥
                if select.select([sys.stdin], [], [], 0) == ([sys.stdin], [], []):
                    key = sys.stdin.read(1).lower()
                    if key == 's':
                        self.display_pnl_stats()
                    elif key == 'q':
                        logging.info("ğŸ‘‹ ç”¨æˆ·é€‰æ‹©é€€å‡ºç¨‹åº")
                        return True
            return False
        
        def has_pending_trades():
            """æ£€æŸ¥æ˜¯å¦æœ‰å¾…ç»“ç®—çš„äº¤æ˜“"""
            pending_trades = [t for t in self.simulation_records if t.get('status', 'OPEN') == 'OPEN']
            return len(pending_trades) > 0
        
        def should_trade_now(current_time):
            """æ£€æŸ¥æ˜¯å¦å¯ä»¥è¿›è¡Œæ–°äº¤æ˜“"""
            # æ£€æŸ¥æ˜¯å¦æœ‰å¾…ç»“ç®—äº¤æ˜“
            if has_pending_trades():
                return False, "æœ‰å¾…ç»“ç®—äº¤æ˜“"
            
            # æ£€æŸ¥äº¤æ˜“å†·å´æœŸï¼ˆ10åˆ†é’Ÿï¼‰
            if last_trade_time and (current_time - last_trade_time).total_seconds() < 600:
                time_left = 600 - (current_time - last_trade_time).total_seconds()
                return False, f"äº¤æ˜“å†·å´æœŸï¼Œè¿˜éœ€{time_left:.0f}ç§’"
            
            return True, "å¯ä»¥äº¤æ˜“"
        
        def should_run_prediction(current_time, current_price):
            """æ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦è¿è¡Œå®Œæ•´é¢„æµ‹"""
            # ä»·æ ¼å˜åŒ–è§¦å‘
            price_changed = last_price is None or current_price != last_price
            
            # æ—¶é—´è§¦å‘ - æ¯30ç§’è‡³å°‘é¢„æµ‹ä¸€æ¬¡ï¼Œç¡®ä¿ä¸é”™è¿‡æœºä¼š
            time_trigger = (last_prediction_time is None or 
                          (current_time - last_prediction_time).total_seconds() >= 30)
            
            # æ˜¾è‘—ä»·æ ¼å˜åŒ–è§¦å‘ - ä»·æ ¼å˜åŒ–è¶…è¿‡0.05%ç«‹å³é¢„æµ‹
            significant_change = False
            if last_price is not None:
                price_change_pct = abs(current_price - last_price) / last_price * 100
                if price_change_pct >= 0.05:
                    significant_change = True
            
            return price_changed or time_trigger or significant_change
        
        while True:
            try:
                # æ£€æŸ¥ç”¨æˆ·è¾“å…¥
                if check_keyboard_input():
                    break
                
                current_time = datetime.now()
                
                # è·å–å½“å‰ä»·æ ¼ - å¿«é€ŸAPIè°ƒç”¨
                current_price = self.api.get_latest_price('BTCUSDT')
                if current_price is None:
                    print("âš ï¸ è·å–ä»·æ ¼å¤±è´¥ï¼Œé‡è¯•ä¸­...")
                    time.sleep(1)
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å¯ä»¥äº¤æ˜“
                can_trade, trade_status = should_trade_now(current_time)
                
                # æ˜¾ç¤ºå®æ—¶ç›‘æ§ä¿¡æ¯ï¼ˆæ¯100æ¬¡å¾ªç¯æ˜¾ç¤ºä¸€æ¬¡ï¼Œé¿å…åˆ·å±ï¼‰
                loop_count += 1
                if loop_count % 100 == 0:
                    status_emoji = "âœ…" if can_trade else "â³"
                    print(f"{status_emoji} ç›‘æ§ä¸­... ä»·æ ¼: ${current_price:.2f} | çŠ¶æ€: {trade_status} | å¾ªç¯: #{loop_count}")
                
                # æ™ºèƒ½é¢„æµ‹è§¦å‘ - åªåœ¨éœ€è¦æ—¶è¿›è¡Œå®Œæ•´é¢„æµ‹
                if should_run_prediction(current_time, current_price):
                    last_prediction_time = current_time
                    last_price = current_price
                    
                    # æ‰§è¡Œå®Œæ•´é¢„æµ‹åˆ†æ - ä¿æŒæ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡å’Œæƒ…ç»ªåˆ†æ
                    try:
                        prediction_result = self.predict()
                        
                        if prediction_result is not None:
                            confidence = prediction_result['confidence']
                            
                            # æ ¹æ®ç½®ä¿¡åº¦çº§åˆ«è¿›è¡Œä¸åŒå¤„ç†
                            if confidence >= 85:  # æé«˜ç½®ä¿¡åº¦ - ç«‹å³äº¤æ˜“
                                if can_trade:
                                    prediction_result['bet_amount'] = 5
                                    
                                    # ç«‹å³æé†’ - å¤šæ¬¡æç¤ºéŸ³
                                    for _ in range(3):
                                        print('\a')  # ç³»ç»Ÿæç¤ºéŸ³
                                        time.sleep(0.1)
                                    
                                    print(f"\n{'ğŸš¨' * 60}")
                                    print(f"ğŸš¨ğŸš¨ğŸš¨ å‘ç°æé«˜ç½®ä¿¡åº¦äº¤æ˜“æœºä¼šï¼ğŸš¨ğŸš¨ğŸš¨")
                                    print(f"â° æ—¶é—´: {current_time.strftime('%H:%M:%S')}")
                                    print(f"ğŸ’° ä»·æ ¼: ${current_price:,.2f}")
                                    print(f"ğŸ¯ ä¿¡å·: {prediction_result['trade_signal']}")
                                    print(f"ğŸ“Š æ–¹å‘: é¢„æµ‹10åˆ†é’Ÿåä»·æ ¼{prediction_result['direction']}")
                                    print(f"ğŸ”¥ ç½®ä¿¡åº¦: {confidence:.1f}% (æé«˜)")
                                    print(f"ğŸ’µ æŠ•æ³¨: 5 USDT")
                                    print(f"ğŸ† é¢„æœŸå›æŠ¥: 9 USDT (ç›ˆåˆ©4u)")
                                    
                                    # æ˜¾ç¤ºè¯¦ç»†åˆ†æä¿¡æ¯
                                    if 'technical_strength' in prediction_result:
                                        print(f"ğŸ“ˆ æŠ€æœ¯å¼ºåº¦: {prediction_result['technical_strength']:.3f}")
                                    if 'sentiment_strength' in prediction_result:
                                        print(f"ğŸ˜Š æƒ…ç»ªå¼ºåº¦: {prediction_result['sentiment_strength']:.3f}")
                                    if 'confidence_adjustments' in prediction_result:
                                        print(f"ğŸ”§ ç½®ä¿¡åº¦è°ƒæ•´: {', '.join(prediction_result['confidence_adjustments'])}")
                                    
                                    # æ˜¾ç¤ºé©¬ä¸æ ¼å°”ç­–ç•¥ä¿¡æ¯
                                    print(f"ğŸ’° é©¬ä¸æ ¼å°”æŠ•æ³¨: {self.martingale_bet_amounts[self.current_bet_level]} USDT (çº§åˆ« {self.current_bet_level})")
                                    if self.current_bet_level > 0:
                                        print(f"ğŸ“Š é©¬ä¸æ ¼å°”ç­–ç•¥: ä¹‹å‰äºæŸï¼Œå¢åŠ æŠ•æ³¨é¢ä»¥è¿½å›æŸå¤±")
                                    else:
                                        print(f"ğŸ“Š é©¬ä¸æ ¼å°”ç­–ç•¥: åˆå§‹æŠ•æ³¨é¢")
                                    
                                    print(f"{'ğŸš¨' * 60}\n")
                                    
                                    # æ‰§è¡Œäº¤æ˜“
                                    self.simulate_trade(prediction_result)
                                    last_trade_time = current_time
                                else:
                                    print(f"ğŸ”¥ æé«˜ç½®ä¿¡åº¦ä¿¡å·: {prediction_result['trade_signal']} | ç½®ä¿¡åº¦: {confidence:.1f}% | ä»·æ ¼: ${current_price:.2f} | {trade_status}")
                                
                            elif confidence >= 75:  # é«˜ç½®ä¿¡åº¦ - æé†’ä½†ä¸äº¤æ˜“
                                print(f"ğŸ”¥ é«˜ç½®ä¿¡åº¦ä¿¡å·: {prediction_result['trade_signal']} | ç½®ä¿¡åº¦: {confidence:.1f}% | ä»·æ ¼: ${current_price:.2f}")
                                
                            elif confidence >= 65:  # ä¸­ç­‰ç½®ä¿¡åº¦ - ç®€å•æé†’
                                if loop_count % 50 == 0:  # å‡å°‘æ˜¾ç¤ºé¢‘ç‡
                                    print(f"ğŸ“Š ä¸­ç­‰ç½®ä¿¡åº¦: {prediction_result['trade_signal']} | ç½®ä¿¡åº¦: {confidence:.1f}% | ä»·æ ¼: ${current_price:.2f}")
                            
                            # ä½ç½®ä¿¡åº¦ä¸æ˜¾ç¤ºï¼Œé¿å…åˆ·å±
                            
                    except Exception as e:
                        if loop_count % 200 == 0:  # æ¯200æ¬¡å¾ªç¯æ‰æ˜¾ç¤ºä¸€æ¬¡é”™è¯¯ï¼Œé¿å…åˆ·å±
                            print(f"âš ï¸ é¢„æµ‹åˆ†æå‡ºé”™: {e}")
                
                # å¤„ç†å®šæ—¶ä»»åŠ¡ï¼ˆæ£€æŸ¥äº¤æ˜“ç»“æœï¼‰
                schedule.run_pending()
                
                # ä¼˜åŒ–çš„ç­‰å¾…æ—¶é—´ - 0.5ç§’ç¡®ä¿å®æ—¶æ€§ï¼Œä½†ä¸ä¼šè¿‡åº¦æ¶ˆè€—èµ„æº
                time.sleep(0.5)
                
            except KeyboardInterrupt:
                logging.info("âš ï¸ ç”¨æˆ·ä¸­æ–­ç›‘æ§")
                break
            except Exception as e:
                logging.error(f"âŒ ç›‘æ§å‡ºé”™: {e}")
                time.sleep(2)  # é”™è¯¯æ—¶ç¨å¾®ç­‰å¾…ä¸€ä¸‹

# ä¸»å‡½æ•°
def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='ğŸš€ æ¯”ç‰¹å¸ä»·æ ¼é¢„æµ‹ç³»ç»Ÿ - æ™ºèƒ½åˆçº¦äº¤æ˜“åŠ©æ‰‹')
    parser.add_argument('--train', action='store_true', help='è®­ç»ƒæ–°æ¨¡å‹')
    parser.add_argument('--backtest', action='store_true', help='è¿›è¡Œå†å²å›æµ‹')
    parser.add_argument('--start_date', type=str, help='å›æµ‹å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼: YYYY-MM-DD')
    parser.add_argument('--end_date', type=str, help='å›æµ‹ç»“æŸæ—¥æœŸï¼Œæ ¼å¼: YYYY-MM-DD')
    parser.add_argument('--days', type=int, default=30, help='å›æµ‹å¤©æ•°(å¦‚æœæœªæŒ‡å®šæ—¥æœŸ)')
    parser.add_argument('--interval', type=int, default=5, help='æ•°æ®åˆ·æ–°é—´éš”(ç§’)ï¼Œé»˜è®¤5ç§’')
    parser.add_argument('--continuous', action='store_true', help='å¯ç”¨è¿ç»­å®æ—¶åˆ†ææ¨¡å¼')
    parser.add_argument('--stats', action='store_true', help='æ˜¾ç¤ºæ€»ä½“ç›ˆäºç»Ÿè®¡')
    args = parser.parse_args()
    
    logging.info("ğŸš€ å¯åŠ¨æ¯”ç‰¹å¸ä»·æ ¼é¢„æµ‹ç³»ç»Ÿ - æ™ºèƒ½åˆçº¦äº¤æ˜“åŠ©æ‰‹")
    logging.info("ğŸ“Š æ”¯æŒå¤šæ—¶é—´å‘¨æœŸåˆ†æ | ğŸ” å¤§å•æ£€æµ‹ | ğŸ“ˆ å¸‚åœºæ·±åº¦åˆ†æ")
    logging.info("ğŸ° äº‹ä»¶åˆçº¦æ¨¡å¼: æŠ•æ³¨5uï¼Œé¢„æµ‹æ­£ç¡®è·å¾—9uï¼Œé”™è¯¯å½’é›¶")
    
    # åŠ è½½é…ç½®
    config = load_config()
    
    # æ£€æŸ¥APIå¯†é’¥é…ç½®
    if not config['api_key'] or not config['api_secret']:
        print("ğŸ”‘ è¯·è¾“å…¥æ‚¨çš„å¸å®‰APIä¿¡æ¯:")
        api_key = input("API Key: ")
        api_secret = input("API Secret: ")
        config['api_key'] = api_key
        config['api_secret'] = api_secret
        save_config(config)
    
    # åˆ›å»ºé¢„æµ‹å™¨
    predictor = BitcoinPredictor(config)
    
    # åŠ è½½å†å²äº¤æ˜“è®°å½•
    predictor.load_simulation_records()
    
    # å¦‚æœåªæ˜¯æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
    if args.stats:
        predictor.display_pnl_stats()
        return
    
    # å¦‚æœæŒ‡å®šäº†è®­ç»ƒæ¨¡å¼
    if args.train:
        logging.info("ğŸ”§ å¼ºåˆ¶è®­ç»ƒæ–°æ¨¡å‹...")
        # åˆ é™¤æ—§æ¨¡å‹æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if os.path.exists('model.pth'):
            logging.info("ğŸ“ åˆ é™¤æ—§æ¨¡å‹æ–‡ä»¶...")
            try:
                os.remove('model.pth')
                logging.info("âœ… æ—§æ¨¡å‹æ–‡ä»¶å·²åˆ é™¤")
            except Exception as e:
                logging.error(f"âŒ åˆ é™¤æ—§æ¨¡å‹æ–‡ä»¶å¤±è´¥: {e}")
        
        if predictor.train():
            logging.info("ğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        else:
            logging.error("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
        return
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ¨¡å‹ï¼Œè®­ç»ƒä¸€ä¸ªæ–°æ¨¡å‹
    if predictor.model is None:
        logging.info("ğŸ”§ æ²¡æœ‰æ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¼€å§‹è®­ç»ƒæ–°æ¨¡å‹...")
        
        # å¦‚æœåŠ è½½æ¨¡å‹å¤±è´¥ä½†æ–‡ä»¶å­˜åœ¨ï¼Œå¯èƒ½æ˜¯æ¨¡å‹ä¸å½“å‰ä»£ç ä¸å…¼å®¹
        # åˆ é™¤æ—§æ¨¡å‹æ–‡ä»¶å¹¶é‡æ–°è®­ç»ƒ
        if os.path.exists('model.pth'):
            logging.warning("âš ï¸ å‘ç°ä¸å…¼å®¹çš„æ¨¡å‹æ–‡ä»¶ï¼Œåˆ é™¤å¹¶é‡æ–°è®­ç»ƒ...")
            try:
                os.remove('model.pth')
            except Exception as e:
                logging.error(f"âŒ åˆ é™¤æ—§æ¨¡å‹æ–‡ä»¶å¤±è´¥: {e}")
        
        if not predictor.train():
            logging.error("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
            return
    
    # å¦‚æœæŒ‡å®šäº†å›æµ‹æ¨¡å¼
    if args.backtest:
        logging.info("ğŸ“Š å¼€å§‹æ‰§è¡Œå†å²å›æµ‹...")
        predictor.backtest(args.start_date, args.end_date, args.days)
        return
    
    # è·å–æ•°æ®åˆ·æ–°é—´éš”
    refresh_interval = args.interval
    
    # è®°å½•ä¸Šæ¬¡é¢„æµ‹æ—¶é—´å’Œä»·æ ¼ï¼Œé¿å…é‡å¤é¢„æµ‹
    last_prediction_time = 0
    last_price = 0
    prediction_cooldown = 60  # é¢„æµ‹å†·å´æ—¶é—´60ç§’
    
    # ç¨‹åºç»“æŸæ—¶è®¡ç®—æœ€ç»ˆç»©æ•ˆ
    try:
        predictor.calculate_performance()
        predictor.plot_performance()
    except:
        pass
    logging.info("ğŸ”š ç¨‹åºç»“æŸ")

    # å¯åŠ¨è¿ç»­æ¨¡å¼æˆ–å®šæ—¶æ¨¡å¼
    # é»˜è®¤å¯åŠ¨è¿ç»­ç›‘æ§æ¨¡å¼ï¼Œé™¤éæ˜ç¡®æŒ‡å®šå…¶ä»–æ¨¡å¼
    if not args.backtest and not args.stats and not args.train:
        logging.info("ğŸ”„ å¯åŠ¨è¿ç»­å®æ—¶åˆ†ææ¨¡å¼ï¼ˆé»˜è®¤æ¨¡å¼ï¼‰")
        logging.info("ğŸ‘ï¸ å®Œæ•´é¢„æµ‹è¿‡ç¨‹å±•ç¤º: æ¯æ¬¡åˆ†æéƒ½ä¼šæ˜¾ç¤ºè¯¦ç»†æ­¥éª¤")
        logging.info("ğŸ“Š åŒ…å«: æ•°æ®è·å–â†’æŠ€æœ¯æŒ‡æ ‡â†’AIæ¨¡å‹â†’ç½®ä¿¡åº¦è®¡ç®—â†’äº¤æ˜“å†³ç­–")
        logging.info("âš¡ åªåœ¨æé«˜ç½®ä¿¡åº¦(â‰¥85%)æ—¶æ‰ä¼šæç¤ºäº¤æ˜“")
        logging.info("ğŸš¨ å‘ç°æä½³æœºä¼šæ—¶ä¼šè¿ç»­æç¤ºéŸ³+é†’ç›®æç¤º")
        logging.info("â° æ¯ç¬”äº¤æ˜“å°†åœ¨10åˆ†é’Ÿåè‡ªåŠ¨éªŒè¯ç»“æœ")
        logging.info("ğŸ’° é©¬ä¸æ ¼å°”æŠ•æ³¨ç­–ç•¥: åˆå§‹5Uï¼Œè¾“åˆ™ç¿»å€(10Uâ†’30Uâ†’90Uâ†’250U)ï¼Œèµ¢åˆ™å›åˆ°5U")
        logging.info("âŒ¨ï¸  è¿è¡Œä¸­æŒ‰é”®åŠŸèƒ½: 's' - æŸ¥çœ‹ç»Ÿè®¡  'q' - é€€å‡º")
        
        # å®šæ—¶ä»»åŠ¡ - æ¯å¤©è®¡ç®—ä¸€æ¬¡ç»©æ•ˆ
        schedule.every().day.at("00:00").do(predictor.calculate_performance)
        schedule.every().day.at("00:01").do(predictor.plot_performance)
        
        # ç«‹å³è¿›è¡Œä¸€æ¬¡é¢„æµ‹å’Œå¯åŠ¨è¿ç»­ç›‘æ§
        predictor.continuous_predict_and_trade()
    elif args.continuous:
        # å…¼å®¹æ—§çš„--continuouså‚æ•°
        logging.info("ğŸ”„ å¯åŠ¨è¿ç»­å®æ—¶åˆ†ææ¨¡å¼ï¼ˆé€šè¿‡--continuouså‚æ•°ï¼‰")
        logging.info("ğŸ‘ï¸ å®Œæ•´é¢„æµ‹è¿‡ç¨‹å±•ç¤º: æ¯æ¬¡åˆ†æéƒ½ä¼šæ˜¾ç¤ºè¯¦ç»†æ­¥éª¤")
        logging.info("ğŸ“Š åŒ…å«: æ•°æ®è·å–â†’æŠ€æœ¯æŒ‡æ ‡â†’AIæ¨¡å‹â†’ç½®ä¿¡åº¦è®¡ç®—â†’äº¤æ˜“å†³ç­–")
        logging.info("âš¡ åªåœ¨æé«˜ç½®ä¿¡åº¦(â‰¥85%)æ—¶æ‰ä¼šæç¤ºäº¤æ˜“")
        logging.info("ğŸš¨ å‘ç°æä½³æœºä¼šæ—¶ä¼šè¿ç»­æç¤ºéŸ³+é†’ç›®æç¤º")
        logging.info("â° æ¯ç¬”äº¤æ˜“å°†åœ¨10åˆ†é’Ÿåè‡ªåŠ¨éªŒè¯ç»“æœ")
        logging.info("ğŸ’° é©¬ä¸æ ¼å°”æŠ•æ³¨ç­–ç•¥: åˆå§‹5Uï¼Œè¾“åˆ™ç¿»å€(10Uâ†’30Uâ†’90Uâ†’250U)ï¼Œèµ¢åˆ™å›åˆ°5U")
        logging.info("âŒ¨ï¸  è¿è¡Œä¸­æŒ‰é”®åŠŸèƒ½: 's' - æŸ¥çœ‹ç»Ÿè®¡  'q' - é€€å‡º")
        
        # å®šæ—¶ä»»åŠ¡ - æ¯å¤©è®¡ç®—ä¸€æ¬¡ç»©æ•ˆ
        schedule.every().day.at("00:00").do(predictor.calculate_performance)
        schedule.every().day.at("00:01").do(predictor.plot_performance)
        
        # ç«‹å³è¿›è¡Œä¸€æ¬¡é¢„æµ‹å’Œå¯åŠ¨è¿ç»­ç›‘æ§
        predictor.continuous_predict_and_trade()

if __name__ == "__main__":
    main() 